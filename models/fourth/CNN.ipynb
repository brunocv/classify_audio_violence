{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural Network\n",
    "\n",
    "### Part 1 - Building the CNN\n",
    "\n",
    "#### Importing the Tensorflow libraries and packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor Flow Version: 2.6.0\n",
      "Keras Version: 2.6.0\n",
      "\n",
      "Python 3.8.13 | packaged by conda-forge | (default, Mar 25 2022, 05:59:45) [MSC v.1929 64 bit (AMD64)]\n",
      "Pandas 1.4.3\n",
      "Scikit-Learn 1.1.1\n",
      "GPU is available\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "import tensorflow.keras\n",
    "import pandas as pd\n",
    "import sklearn as sk\n",
    "import tensorflow as tf\n",
    "\n",
    "print(f\"Tensor Flow Version: {tf.__version__}\")\n",
    "print(f\"Keras Version: {tensorflow.keras.__version__}\")\n",
    "print()\n",
    "print(f\"Python {sys.version}\")\n",
    "print(f\"Pandas {pd.__version__}\")\n",
    "print(f\"Scikit-Learn {sk.__version__}\")\n",
    "gpu = len(tf.config.list_physical_devices('GPU'))>0\n",
    "print(\"GPU is\", \"available\" if gpu else \"NOT AVAILABLE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the TensorBoard notebook extension\n",
    "%load_ext tensorboard\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, GlobalAveragePooling2D\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = Sequential()\n",
    "\n",
    "#classes = 2\n",
    "\n",
    "#Kernels usually 1x1 | 3x3 | 5x5\n",
    "\n",
    "#Adding a convolutional layer\n",
    "classifier.add(Conv2D(8, (3, 3), input_shape = (150, 150, 3), padding='same', activation = 'relu'))\n",
    "classifier.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "#Adding a second convolutional layer\n",
    "classifier.add(Conv2D(16, (3, 3), padding='same', activation = 'relu'))\n",
    "classifier.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "#Flattening\n",
    "classifier.add(Flatten())\n",
    "\n",
    "#Full connection\n",
    "classifier.add(Dense(units = 32, activation = 'relu'))\n",
    "classifier.add(Dropout(0.30))\n",
    "classifier.add(Dense(units = 1, activation= 'sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's double check the model description:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 150, 150, 8)       224       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 75, 75, 8)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 75, 75, 16)        1168      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 37, 37, 16)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 21904)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 32)                700960    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 702,385\n",
      "Trainable params: 702,385\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "classifier.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "opt = Adam(learning_rate=0.00001)\n",
    "classifier.compile(optimizer = opt, loss = 'binary_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2 - Fitting the CNN to the images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2202 images belonging to 2 classes.\n",
      "Found 550 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "path_dir = '../../dataset/train'\n",
    "parth_dir_test = '../../dataset/test'\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "                    rescale=1./255,\n",
    "                    validation_split = 0.2)\n",
    "\n",
    "train_generator = datagen.flow_from_directory(\n",
    "    path_dir,\n",
    "    target_size=(150,150),\n",
    "    shuffle=True,\n",
    "    subset='training',\n",
    "    batch_size = 64,\n",
    "    seed = 11,\n",
    "    class_mode = 'binary'\n",
    ")\n",
    "validation_generator = datagen.flow_from_directory(\n",
    "    path_dir,\n",
    "    target_size=(150,150),\n",
    "    subset='validation',\n",
    "    batch_size = 64,\n",
    "    seed = 11,\n",
    "    class_mode = 'binary'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'nonviolence': 0, 'violence': 1}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_generator.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, TensorBoard\n",
    "import datetime\n",
    "\n",
    "#rm -rf /logs/\n",
    "\n",
    "es = EarlyStopping(monitor='val_loss', patience=30)\n",
    "mc = ModelCheckpoint('best_cnn.h5', monitor='val_loss', mode='min', save_best_only=True)\n",
    "reduceLR = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=30)\n",
    "\n",
    "# Create a TensorBoard callback\n",
    "log_dir = \"logs\\\\fit\\\\\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "35/35 [==============================] - 11s 248ms/step - loss: 0.6947 - accuracy: 0.5141 - val_loss: 0.6889 - val_accuracy: 0.5000\n",
      "Epoch 2/200\n",
      "35/35 [==============================] - 8s 228ms/step - loss: 0.6870 - accuracy: 0.5563 - val_loss: 0.6815 - val_accuracy: 0.6564\n",
      "Epoch 3/200\n",
      "35/35 [==============================] - 8s 232ms/step - loss: 0.6818 - accuracy: 0.5767 - val_loss: 0.6713 - val_accuracy: 0.7327\n",
      "Epoch 4/200\n",
      "35/35 [==============================] - 8s 231ms/step - loss: 0.6729 - accuracy: 0.6521 - val_loss: 0.6629 - val_accuracy: 0.7091\n",
      "Epoch 5/200\n",
      "35/35 [==============================] - 8s 230ms/step - loss: 0.6630 - accuracy: 0.6798 - val_loss: 0.6524 - val_accuracy: 0.7418\n",
      "Epoch 6/200\n",
      "35/35 [==============================] - 8s 228ms/step - loss: 0.6562 - accuracy: 0.6689 - val_loss: 0.6417 - val_accuracy: 0.7091\n",
      "Epoch 7/200\n",
      "35/35 [==============================] - 8s 232ms/step - loss: 0.6455 - accuracy: 0.7016 - val_loss: 0.6281 - val_accuracy: 0.7673\n",
      "Epoch 8/200\n",
      "35/35 [==============================] - 8s 231ms/step - loss: 0.6354 - accuracy: 0.7212 - val_loss: 0.6140 - val_accuracy: 0.8255\n",
      "Epoch 9/200\n",
      "35/35 [==============================] - 8s 234ms/step - loss: 0.6255 - accuracy: 0.7262 - val_loss: 0.6013 - val_accuracy: 0.8236\n",
      "Epoch 10/200\n",
      "35/35 [==============================] - 8s 232ms/step - loss: 0.6133 - accuracy: 0.7366 - val_loss: 0.5894 - val_accuracy: 0.8182\n",
      "Epoch 11/200\n",
      "35/35 [==============================] - 8s 232ms/step - loss: 0.6052 - accuracy: 0.7343 - val_loss: 0.5793 - val_accuracy: 0.7873\n",
      "Epoch 12/200\n",
      "35/35 [==============================] - 8s 228ms/step - loss: 0.5994 - accuracy: 0.7302 - val_loss: 0.5661 - val_accuracy: 0.8327\n",
      "Epoch 13/200\n",
      "35/35 [==============================] - 8s 229ms/step - loss: 0.5893 - accuracy: 0.7275 - val_loss: 0.5597 - val_accuracy: 0.7982\n",
      "Epoch 14/200\n",
      "35/35 [==============================] - 8s 233ms/step - loss: 0.5790 - accuracy: 0.7493 - val_loss: 0.5493 - val_accuracy: 0.8145\n",
      "Epoch 15/200\n",
      "35/35 [==============================] - 8s 233ms/step - loss: 0.5722 - accuracy: 0.7493 - val_loss: 0.5447 - val_accuracy: 0.7945\n",
      "Epoch 16/200\n",
      "35/35 [==============================] - 8s 231ms/step - loss: 0.5679 - accuracy: 0.7312 - val_loss: 0.5433 - val_accuracy: 0.7764\n",
      "Epoch 17/200\n",
      "35/35 [==============================] - 8s 229ms/step - loss: 0.5606 - accuracy: 0.7548 - val_loss: 0.5292 - val_accuracy: 0.8091\n",
      "Epoch 18/200\n",
      "35/35 [==============================] - 8s 232ms/step - loss: 0.5557 - accuracy: 0.7548 - val_loss: 0.5231 - val_accuracy: 0.8127\n",
      "Epoch 19/200\n",
      "35/35 [==============================] - 8s 229ms/step - loss: 0.5480 - accuracy: 0.7629 - val_loss: 0.5178 - val_accuracy: 0.8091\n",
      "Epoch 20/200\n",
      "35/35 [==============================] - 8s 230ms/step - loss: 0.5427 - accuracy: 0.7611 - val_loss: 0.5115 - val_accuracy: 0.8127\n",
      "Epoch 21/200\n",
      "35/35 [==============================] - 8s 230ms/step - loss: 0.5411 - accuracy: 0.7639 - val_loss: 0.5025 - val_accuracy: 0.8364\n",
      "Epoch 22/200\n",
      "35/35 [==============================] - 8s 233ms/step - loss: 0.5324 - accuracy: 0.7702 - val_loss: 0.4979 - val_accuracy: 0.8291\n",
      "Epoch 23/200\n",
      "35/35 [==============================] - 8s 229ms/step - loss: 0.5283 - accuracy: 0.7675 - val_loss: 0.4984 - val_accuracy: 0.8200\n",
      "Epoch 24/200\n",
      "35/35 [==============================] - 8s 230ms/step - loss: 0.5254 - accuracy: 0.7711 - val_loss: 0.4874 - val_accuracy: 0.8327\n",
      "Epoch 25/200\n",
      "35/35 [==============================] - 8s 232ms/step - loss: 0.5167 - accuracy: 0.7725 - val_loss: 0.4847 - val_accuracy: 0.8273\n",
      "Epoch 26/200\n",
      "35/35 [==============================] - 8s 229ms/step - loss: 0.5183 - accuracy: 0.7720 - val_loss: 0.4782 - val_accuracy: 0.8473\n",
      "Epoch 27/200\n",
      "35/35 [==============================] - 8s 229ms/step - loss: 0.5107 - accuracy: 0.7802 - val_loss: 0.4779 - val_accuracy: 0.8291\n",
      "Epoch 28/200\n",
      "35/35 [==============================] - 8s 230ms/step - loss: 0.5063 - accuracy: 0.7779 - val_loss: 0.4703 - val_accuracy: 0.8473\n",
      "Epoch 29/200\n",
      "35/35 [==============================] - 8s 230ms/step - loss: 0.5059 - accuracy: 0.7766 - val_loss: 0.4661 - val_accuracy: 0.8418\n",
      "Epoch 30/200\n",
      "35/35 [==============================] - 8s 226ms/step - loss: 0.5018 - accuracy: 0.7897 - val_loss: 0.4644 - val_accuracy: 0.8382\n",
      "Epoch 31/200\n",
      "35/35 [==============================] - 8s 231ms/step - loss: 0.5027 - accuracy: 0.7738 - val_loss: 0.4610 - val_accuracy: 0.8418\n",
      "Epoch 32/200\n",
      "35/35 [==============================] - 8s 227ms/step - loss: 0.4917 - accuracy: 0.7897 - val_loss: 0.4564 - val_accuracy: 0.8491\n",
      "Epoch 33/200\n",
      "35/35 [==============================] - 8s 236ms/step - loss: 0.4981 - accuracy: 0.7934 - val_loss: 0.4549 - val_accuracy: 0.8564\n",
      "Epoch 34/200\n",
      "35/35 [==============================] - 8s 236ms/step - loss: 0.4904 - accuracy: 0.7920 - val_loss: 0.4515 - val_accuracy: 0.8418\n",
      "Epoch 35/200\n",
      "35/35 [==============================] - 8s 228ms/step - loss: 0.4945 - accuracy: 0.7761 - val_loss: 0.4474 - val_accuracy: 0.8564\n",
      "Epoch 36/200\n",
      "35/35 [==============================] - 8s 230ms/step - loss: 0.4858 - accuracy: 0.7952 - val_loss: 0.4444 - val_accuracy: 0.8527\n",
      "Epoch 37/200\n",
      "35/35 [==============================] - 8s 228ms/step - loss: 0.4834 - accuracy: 0.7943 - val_loss: 0.4420 - val_accuracy: 0.8527\n",
      "Epoch 38/200\n",
      "35/35 [==============================] - 8s 230ms/step - loss: 0.4791 - accuracy: 0.7993 - val_loss: 0.4400 - val_accuracy: 0.8509\n",
      "Epoch 39/200\n",
      "35/35 [==============================] - 8s 226ms/step - loss: 0.4812 - accuracy: 0.7911 - val_loss: 0.4370 - val_accuracy: 0.8564\n",
      "Epoch 40/200\n",
      "35/35 [==============================] - 8s 229ms/step - loss: 0.4754 - accuracy: 0.7929 - val_loss: 0.4341 - val_accuracy: 0.8636\n",
      "Epoch 41/200\n",
      "35/35 [==============================] - 8s 227ms/step - loss: 0.4734 - accuracy: 0.7961 - val_loss: 0.4318 - val_accuracy: 0.8618\n",
      "Epoch 42/200\n",
      "35/35 [==============================] - 8s 226ms/step - loss: 0.4693 - accuracy: 0.8006 - val_loss: 0.4303 - val_accuracy: 0.8600\n",
      "Epoch 43/200\n",
      "35/35 [==============================] - 8s 225ms/step - loss: 0.4712 - accuracy: 0.7984 - val_loss: 0.4282 - val_accuracy: 0.8582\n",
      "Epoch 44/200\n",
      "35/35 [==============================] - 8s 234ms/step - loss: 0.4649 - accuracy: 0.8052 - val_loss: 0.4268 - val_accuracy: 0.8582\n",
      "Epoch 45/200\n",
      "35/35 [==============================] - 8s 226ms/step - loss: 0.4676 - accuracy: 0.7997 - val_loss: 0.4238 - val_accuracy: 0.8600\n",
      "Epoch 46/200\n",
      "35/35 [==============================] - 8s 226ms/step - loss: 0.4618 - accuracy: 0.8097 - val_loss: 0.4209 - val_accuracy: 0.8673\n",
      "Epoch 47/200\n",
      "35/35 [==============================] - 8s 226ms/step - loss: 0.4601 - accuracy: 0.8097 - val_loss: 0.4215 - val_accuracy: 0.8545\n",
      "Epoch 48/200\n",
      "35/35 [==============================] - 8s 234ms/step - loss: 0.4584 - accuracy: 0.8034 - val_loss: 0.4174 - val_accuracy: 0.8691\n",
      "Epoch 49/200\n",
      "35/35 [==============================] - 8s 224ms/step - loss: 0.4538 - accuracy: 0.8052 - val_loss: 0.4158 - val_accuracy: 0.8600\n",
      "Epoch 50/200\n",
      "35/35 [==============================] - 8s 226ms/step - loss: 0.4578 - accuracy: 0.7984 - val_loss: 0.4231 - val_accuracy: 0.8418\n",
      "Epoch 51/200\n",
      "35/35 [==============================] - 8s 231ms/step - loss: 0.4534 - accuracy: 0.8097 - val_loss: 0.4129 - val_accuracy: 0.8600\n",
      "Epoch 52/200\n",
      "35/35 [==============================] - 8s 229ms/step - loss: 0.4489 - accuracy: 0.8115 - val_loss: 0.4147 - val_accuracy: 0.8582\n",
      "Epoch 53/200\n",
      "35/35 [==============================] - 8s 225ms/step - loss: 0.4482 - accuracy: 0.8129 - val_loss: 0.4100 - val_accuracy: 0.8582\n",
      "Epoch 54/200\n",
      "35/35 [==============================] - 8s 225ms/step - loss: 0.4470 - accuracy: 0.8102 - val_loss: 0.4085 - val_accuracy: 0.8709\n",
      "Epoch 55/200\n",
      "35/35 [==============================] - 8s 228ms/step - loss: 0.4436 - accuracy: 0.8179 - val_loss: 0.4085 - val_accuracy: 0.8509\n",
      "Epoch 56/200\n",
      "35/35 [==============================] - 8s 227ms/step - loss: 0.4402 - accuracy: 0.8097 - val_loss: 0.4081 - val_accuracy: 0.8436\n",
      "Epoch 57/200\n",
      "35/35 [==============================] - 8s 226ms/step - loss: 0.4399 - accuracy: 0.8138 - val_loss: 0.4057 - val_accuracy: 0.8491\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/200\n",
      "35/35 [==============================] - 8s 226ms/step - loss: 0.4403 - accuracy: 0.8152 - val_loss: 0.4032 - val_accuracy: 0.8582\n",
      "Epoch 59/200\n",
      "35/35 [==============================] - 8s 227ms/step - loss: 0.4332 - accuracy: 0.8161 - val_loss: 0.4030 - val_accuracy: 0.8509\n",
      "Epoch 60/200\n",
      "35/35 [==============================] - 8s 231ms/step - loss: 0.4376 - accuracy: 0.8152 - val_loss: 0.4011 - val_accuracy: 0.8618\n",
      "Epoch 61/200\n",
      "35/35 [==============================] - 8s 225ms/step - loss: 0.4327 - accuracy: 0.8188 - val_loss: 0.3999 - val_accuracy: 0.8618\n",
      "Epoch 62/200\n",
      "35/35 [==============================] - 8s 227ms/step - loss: 0.4359 - accuracy: 0.8179 - val_loss: 0.3989 - val_accuracy: 0.8673\n",
      "Epoch 63/200\n",
      "35/35 [==============================] - 8s 226ms/step - loss: 0.4407 - accuracy: 0.8211 - val_loss: 0.3987 - val_accuracy: 0.8727\n",
      "Epoch 64/200\n",
      "35/35 [==============================] - 8s 229ms/step - loss: 0.4316 - accuracy: 0.8265 - val_loss: 0.3965 - val_accuracy: 0.8709\n",
      "Epoch 65/200\n",
      "35/35 [==============================] - 8s 225ms/step - loss: 0.4307 - accuracy: 0.8229 - val_loss: 0.3953 - val_accuracy: 0.8709\n",
      "Epoch 66/200\n",
      "35/35 [==============================] - 8s 226ms/step - loss: 0.4301 - accuracy: 0.8170 - val_loss: 0.3948 - val_accuracy: 0.8709\n",
      "Epoch 67/200\n",
      "35/35 [==============================] - 8s 227ms/step - loss: 0.4272 - accuracy: 0.8179 - val_loss: 0.3936 - val_accuracy: 0.8691\n",
      "Epoch 68/200\n",
      "35/35 [==============================] - 8s 231ms/step - loss: 0.4263 - accuracy: 0.8256 - val_loss: 0.3960 - val_accuracy: 0.8473\n",
      "Epoch 69/200\n",
      "35/35 [==============================] - 8s 229ms/step - loss: 0.4264 - accuracy: 0.8297 - val_loss: 0.3932 - val_accuracy: 0.8564\n",
      "Epoch 70/200\n",
      "35/35 [==============================] - 8s 232ms/step - loss: 0.4255 - accuracy: 0.8224 - val_loss: 0.3924 - val_accuracy: 0.8655\n",
      "Epoch 71/200\n",
      "35/35 [==============================] - 8s 227ms/step - loss: 0.4199 - accuracy: 0.8252 - val_loss: 0.3897 - val_accuracy: 0.8655\n",
      "Epoch 72/200\n",
      "35/35 [==============================] - 8s 227ms/step - loss: 0.4217 - accuracy: 0.8261 - val_loss: 0.3917 - val_accuracy: 0.8564\n",
      "Epoch 73/200\n",
      "35/35 [==============================] - 8s 228ms/step - loss: 0.4189 - accuracy: 0.8243 - val_loss: 0.3885 - val_accuracy: 0.8600\n",
      "Epoch 74/200\n",
      "35/35 [==============================] - 8s 233ms/step - loss: 0.4180 - accuracy: 0.8238 - val_loss: 0.3905 - val_accuracy: 0.8491\n",
      "Epoch 75/200\n",
      "35/35 [==============================] - 8s 225ms/step - loss: 0.4145 - accuracy: 0.8206 - val_loss: 0.3855 - val_accuracy: 0.8691\n",
      "Epoch 76/200\n",
      "35/35 [==============================] - 8s 229ms/step - loss: 0.4121 - accuracy: 0.8292 - val_loss: 0.3868 - val_accuracy: 0.8473\n",
      "Epoch 77/200\n",
      "35/35 [==============================] - 8s 231ms/step - loss: 0.4181 - accuracy: 0.8224 - val_loss: 0.3837 - val_accuracy: 0.8727\n",
      "Epoch 78/200\n",
      "35/35 [==============================] - 8s 225ms/step - loss: 0.4151 - accuracy: 0.8297 - val_loss: 0.3833 - val_accuracy: 0.8709\n",
      "Epoch 79/200\n",
      "35/35 [==============================] - 8s 228ms/step - loss: 0.4185 - accuracy: 0.8256 - val_loss: 0.3834 - val_accuracy: 0.8655\n",
      "Epoch 80/200\n",
      "35/35 [==============================] - 8s 226ms/step - loss: 0.4069 - accuracy: 0.8338 - val_loss: 0.3806 - val_accuracy: 0.8709\n",
      "Epoch 81/200\n",
      "35/35 [==============================] - 8s 229ms/step - loss: 0.4079 - accuracy: 0.8324 - val_loss: 0.3791 - val_accuracy: 0.8709\n",
      "Epoch 82/200\n",
      "35/35 [==============================] - 8s 228ms/step - loss: 0.4064 - accuracy: 0.8347 - val_loss: 0.3787 - val_accuracy: 0.8709\n",
      "Epoch 83/200\n",
      "35/35 [==============================] - 8s 227ms/step - loss: 0.4086 - accuracy: 0.8283 - val_loss: 0.3810 - val_accuracy: 0.8618\n",
      "Epoch 84/200\n",
      "35/35 [==============================] - 8s 232ms/step - loss: 0.4033 - accuracy: 0.8365 - val_loss: 0.3766 - val_accuracy: 0.8709\n",
      "Epoch 85/200\n",
      "35/35 [==============================] - 8s 235ms/step - loss: 0.4060 - accuracy: 0.8338 - val_loss: 0.3769 - val_accuracy: 0.8636\n",
      "Epoch 86/200\n",
      "35/35 [==============================] - 8s 227ms/step - loss: 0.4087 - accuracy: 0.8252 - val_loss: 0.3783 - val_accuracy: 0.8655\n",
      "Epoch 87/200\n",
      "35/35 [==============================] - 8s 227ms/step - loss: 0.3993 - accuracy: 0.8347 - val_loss: 0.3746 - val_accuracy: 0.8764\n",
      "Epoch 88/200\n",
      "35/35 [==============================] - 8s 226ms/step - loss: 0.4013 - accuracy: 0.8320 - val_loss: 0.3911 - val_accuracy: 0.8109\n",
      "Epoch 89/200\n",
      "35/35 [==============================] - 8s 228ms/step - loss: 0.4036 - accuracy: 0.8383 - val_loss: 0.3723 - val_accuracy: 0.8727\n",
      "Epoch 90/200\n",
      "35/35 [==============================] - 8s 225ms/step - loss: 0.4048 - accuracy: 0.8351 - val_loss: 0.3786 - val_accuracy: 0.8527\n",
      "Epoch 91/200\n",
      "35/35 [==============================] - 8s 225ms/step - loss: 0.4023 - accuracy: 0.8338 - val_loss: 0.3714 - val_accuracy: 0.8764\n",
      "Epoch 92/200\n",
      "35/35 [==============================] - 8s 231ms/step - loss: 0.3997 - accuracy: 0.8433 - val_loss: 0.3701 - val_accuracy: 0.8764\n",
      "Epoch 93/200\n",
      "35/35 [==============================] - 8s 230ms/step - loss: 0.3984 - accuracy: 0.8379 - val_loss: 0.3704 - val_accuracy: 0.8727\n",
      "Epoch 94/200\n",
      "35/35 [==============================] - 8s 228ms/step - loss: 0.3955 - accuracy: 0.8424 - val_loss: 0.3678 - val_accuracy: 0.8727\n",
      "Epoch 95/200\n",
      "35/35 [==============================] - 8s 228ms/step - loss: 0.3950 - accuracy: 0.8347 - val_loss: 0.3693 - val_accuracy: 0.8727\n",
      "Epoch 96/200\n",
      "35/35 [==============================] - 8s 230ms/step - loss: 0.3979 - accuracy: 0.8374 - val_loss: 0.3687 - val_accuracy: 0.8727\n",
      "Epoch 97/200\n",
      "35/35 [==============================] - 8s 226ms/step - loss: 0.3924 - accuracy: 0.8411 - val_loss: 0.3697 - val_accuracy: 0.8618\n",
      "Epoch 98/200\n",
      "35/35 [==============================] - 8s 227ms/step - loss: 0.3960 - accuracy: 0.8392 - val_loss: 0.3674 - val_accuracy: 0.8727\n",
      "Epoch 99/200\n",
      "35/35 [==============================] - 8s 226ms/step - loss: 0.3923 - accuracy: 0.8379 - val_loss: 0.3688 - val_accuracy: 0.8582\n",
      "Epoch 100/200\n",
      "35/35 [==============================] - 8s 229ms/step - loss: 0.3953 - accuracy: 0.8356 - val_loss: 0.3668 - val_accuracy: 0.8745\n",
      "Epoch 101/200\n",
      "35/35 [==============================] - 8s 224ms/step - loss: 0.3880 - accuracy: 0.8488 - val_loss: 0.3627 - val_accuracy: 0.8745\n",
      "Epoch 102/200\n",
      "35/35 [==============================] - 8s 228ms/step - loss: 0.3885 - accuracy: 0.8488 - val_loss: 0.3641 - val_accuracy: 0.8727\n",
      "Epoch 103/200\n",
      "35/35 [==============================] - 8s 225ms/step - loss: 0.3865 - accuracy: 0.8470 - val_loss: 0.3626 - val_accuracy: 0.8745\n",
      "Epoch 104/200\n",
      "35/35 [==============================] - 8s 226ms/step - loss: 0.3880 - accuracy: 0.8388 - val_loss: 0.3660 - val_accuracy: 0.8600\n",
      "Epoch 105/200\n",
      "35/35 [==============================] - 8s 228ms/step - loss: 0.3853 - accuracy: 0.8442 - val_loss: 0.3615 - val_accuracy: 0.8764\n",
      "Epoch 106/200\n",
      "35/35 [==============================] - 8s 226ms/step - loss: 0.3852 - accuracy: 0.8424 - val_loss: 0.3597 - val_accuracy: 0.8764\n",
      "Epoch 107/200\n",
      "35/35 [==============================] - 8s 227ms/step - loss: 0.3897 - accuracy: 0.8388 - val_loss: 0.3633 - val_accuracy: 0.8655\n",
      "Epoch 108/200\n",
      "35/35 [==============================] - 8s 226ms/step - loss: 0.3837 - accuracy: 0.8438 - val_loss: 0.3617 - val_accuracy: 0.8691\n",
      "Epoch 109/200\n",
      "35/35 [==============================] - 8s 226ms/step - loss: 0.3836 - accuracy: 0.8510 - val_loss: 0.3588 - val_accuracy: 0.8727\n",
      "Epoch 110/200\n",
      "35/35 [==============================] - 8s 229ms/step - loss: 0.3817 - accuracy: 0.8501 - val_loss: 0.3571 - val_accuracy: 0.8727\n",
      "Epoch 111/200\n",
      "35/35 [==============================] - 8s 240ms/step - loss: 0.3835 - accuracy: 0.8451 - val_loss: 0.3589 - val_accuracy: 0.8745\n",
      "Epoch 112/200\n",
      "35/35 [==============================] - 8s 226ms/step - loss: 0.3808 - accuracy: 0.8447 - val_loss: 0.3564 - val_accuracy: 0.8764\n",
      "Epoch 113/200\n",
      "35/35 [==============================] - 8s 226ms/step - loss: 0.3831 - accuracy: 0.8506 - val_loss: 0.3631 - val_accuracy: 0.8545\n",
      "Epoch 114/200\n",
      "35/35 [==============================] - 8s 225ms/step - loss: 0.3784 - accuracy: 0.8515 - val_loss: 0.3537 - val_accuracy: 0.8745\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 115/200\n",
      "35/35 [==============================] - 8s 227ms/step - loss: 0.3770 - accuracy: 0.8447 - val_loss: 0.3647 - val_accuracy: 0.8382\n",
      "Epoch 116/200\n",
      "35/35 [==============================] - 8s 227ms/step - loss: 0.3780 - accuracy: 0.8488 - val_loss: 0.3536 - val_accuracy: 0.8745\n",
      "Epoch 117/200\n",
      "35/35 [==============================] - 8s 228ms/step - loss: 0.3692 - accuracy: 0.8629 - val_loss: 0.3518 - val_accuracy: 0.8709\n",
      "Epoch 118/200\n",
      "35/35 [==============================] - 8s 229ms/step - loss: 0.3762 - accuracy: 0.8438 - val_loss: 0.3675 - val_accuracy: 0.8273\n",
      "Epoch 119/200\n",
      "35/35 [==============================] - 8s 228ms/step - loss: 0.3754 - accuracy: 0.8420 - val_loss: 0.3510 - val_accuracy: 0.8764\n",
      "Epoch 120/200\n",
      "35/35 [==============================] - 8s 226ms/step - loss: 0.3718 - accuracy: 0.8497 - val_loss: 0.3524 - val_accuracy: 0.8727\n",
      "Epoch 121/200\n",
      "35/35 [==============================] - 8s 227ms/step - loss: 0.3688 - accuracy: 0.8551 - val_loss: 0.3580 - val_accuracy: 0.8473\n",
      "Epoch 122/200\n",
      "35/35 [==============================] - 8s 228ms/step - loss: 0.3677 - accuracy: 0.8606 - val_loss: 0.3486 - val_accuracy: 0.8709\n",
      "Epoch 123/200\n",
      "35/35 [==============================] - 8s 227ms/step - loss: 0.3725 - accuracy: 0.8483 - val_loss: 0.3599 - val_accuracy: 0.8418\n",
      "Epoch 124/200\n",
      "35/35 [==============================] - 8s 229ms/step - loss: 0.3715 - accuracy: 0.8474 - val_loss: 0.3504 - val_accuracy: 0.8709\n",
      "Epoch 125/200\n",
      "35/35 [==============================] - 8s 228ms/step - loss: 0.3673 - accuracy: 0.8510 - val_loss: 0.3469 - val_accuracy: 0.8691\n",
      "Epoch 126/200\n",
      "35/35 [==============================] - 8s 228ms/step - loss: 0.3623 - accuracy: 0.8565 - val_loss: 0.3456 - val_accuracy: 0.8745\n",
      "Epoch 127/200\n",
      "35/35 [==============================] - 8s 226ms/step - loss: 0.3648 - accuracy: 0.8574 - val_loss: 0.3454 - val_accuracy: 0.8764\n",
      "Epoch 128/200\n",
      "35/35 [==============================] - 8s 225ms/step - loss: 0.3581 - accuracy: 0.8488 - val_loss: 0.3479 - val_accuracy: 0.8709\n",
      "Epoch 129/200\n",
      "35/35 [==============================] - 8s 225ms/step - loss: 0.3680 - accuracy: 0.8606 - val_loss: 0.3452 - val_accuracy: 0.8691\n",
      "Epoch 130/200\n",
      "35/35 [==============================] - 8s 230ms/step - loss: 0.3614 - accuracy: 0.8574 - val_loss: 0.3474 - val_accuracy: 0.8691\n",
      "Epoch 131/200\n",
      "35/35 [==============================] - 8s 226ms/step - loss: 0.3628 - accuracy: 0.8529 - val_loss: 0.3438 - val_accuracy: 0.8709\n",
      "Epoch 132/200\n",
      "35/35 [==============================] - 8s 227ms/step - loss: 0.3682 - accuracy: 0.8479 - val_loss: 0.3440 - val_accuracy: 0.8727\n",
      "Epoch 133/200\n",
      "35/35 [==============================] - 8s 230ms/step - loss: 0.3652 - accuracy: 0.8515 - val_loss: 0.3428 - val_accuracy: 0.8727\n",
      "Epoch 134/200\n",
      "35/35 [==============================] - 8s 226ms/step - loss: 0.3608 - accuracy: 0.8560 - val_loss: 0.3483 - val_accuracy: 0.8527\n",
      "Epoch 135/200\n",
      "35/35 [==============================] - 8s 226ms/step - loss: 0.3548 - accuracy: 0.8615 - val_loss: 0.3411 - val_accuracy: 0.8709\n",
      "Epoch 136/200\n",
      "35/35 [==============================] - 8s 226ms/step - loss: 0.3568 - accuracy: 0.8583 - val_loss: 0.3422 - val_accuracy: 0.8709\n",
      "Epoch 137/200\n",
      "35/35 [==============================] - 8s 230ms/step - loss: 0.3552 - accuracy: 0.8692 - val_loss: 0.3414 - val_accuracy: 0.8709\n",
      "Epoch 138/200\n",
      "35/35 [==============================] - 8s 225ms/step - loss: 0.3599 - accuracy: 0.8592 - val_loss: 0.3475 - val_accuracy: 0.8491\n",
      "Epoch 139/200\n",
      "35/35 [==============================] - 8s 225ms/step - loss: 0.3579 - accuracy: 0.8606 - val_loss: 0.3453 - val_accuracy: 0.8582\n",
      "Epoch 140/200\n",
      "35/35 [==============================] - 8s 226ms/step - loss: 0.3519 - accuracy: 0.8574 - val_loss: 0.3385 - val_accuracy: 0.8709\n",
      "Epoch 141/200\n",
      "35/35 [==============================] - 8s 233ms/step - loss: 0.3547 - accuracy: 0.8619 - val_loss: 0.3458 - val_accuracy: 0.8491\n",
      "Epoch 142/200\n",
      "35/35 [==============================] - 8s 229ms/step - loss: 0.3536 - accuracy: 0.8638 - val_loss: 0.3377 - val_accuracy: 0.8745\n",
      "Epoch 143/200\n",
      "35/35 [==============================] - 8s 225ms/step - loss: 0.3498 - accuracy: 0.8638 - val_loss: 0.3386 - val_accuracy: 0.8673\n",
      "Epoch 144/200\n",
      "35/35 [==============================] - 8s 225ms/step - loss: 0.3506 - accuracy: 0.8642 - val_loss: 0.3414 - val_accuracy: 0.8564\n",
      "Epoch 145/200\n",
      "35/35 [==============================] - 8s 230ms/step - loss: 0.3580 - accuracy: 0.8551 - val_loss: 0.3363 - val_accuracy: 0.8727\n",
      "Epoch 146/200\n",
      "35/35 [==============================] - 8s 226ms/step - loss: 0.3479 - accuracy: 0.8588 - val_loss: 0.3366 - val_accuracy: 0.8727\n",
      "Epoch 147/200\n",
      "35/35 [==============================] - 8s 226ms/step - loss: 0.3467 - accuracy: 0.8610 - val_loss: 0.3381 - val_accuracy: 0.8655\n",
      "Epoch 148/200\n",
      "35/35 [==============================] - 8s 229ms/step - loss: 0.3509 - accuracy: 0.8556 - val_loss: 0.3405 - val_accuracy: 0.8618\n",
      "Epoch 149/200\n",
      "35/35 [==============================] - 8s 225ms/step - loss: 0.3491 - accuracy: 0.8697 - val_loss: 0.3436 - val_accuracy: 0.8400\n",
      "Epoch 150/200\n",
      "35/35 [==============================] - 8s 225ms/step - loss: 0.3471 - accuracy: 0.8647 - val_loss: 0.3353 - val_accuracy: 0.8655\n",
      "Epoch 151/200\n",
      "35/35 [==============================] - 8s 226ms/step - loss: 0.3479 - accuracy: 0.8665 - val_loss: 0.3400 - val_accuracy: 0.8582\n",
      "Epoch 152/200\n",
      "35/35 [==============================] - 8s 234ms/step - loss: 0.3396 - accuracy: 0.8633 - val_loss: 0.3361 - val_accuracy: 0.8618\n",
      "Epoch 153/200\n",
      "35/35 [==============================] - 8s 227ms/step - loss: 0.3461 - accuracy: 0.8633 - val_loss: 0.3357 - val_accuracy: 0.8655\n",
      "Epoch 154/200\n",
      "35/35 [==============================] - 8s 228ms/step - loss: 0.3430 - accuracy: 0.8719 - val_loss: 0.3361 - val_accuracy: 0.8618\n",
      "Epoch 155/200\n",
      "35/35 [==============================] - 8s 224ms/step - loss: 0.3411 - accuracy: 0.8742 - val_loss: 0.3384 - val_accuracy: 0.8545\n",
      "Epoch 156/200\n",
      "35/35 [==============================] - 8s 226ms/step - loss: 0.3428 - accuracy: 0.8642 - val_loss: 0.3312 - val_accuracy: 0.8691\n",
      "Epoch 157/200\n",
      "35/35 [==============================] - 8s 227ms/step - loss: 0.3386 - accuracy: 0.8742 - val_loss: 0.3391 - val_accuracy: 0.8491\n",
      "Epoch 158/200\n",
      "35/35 [==============================] - 8s 226ms/step - loss: 0.3408 - accuracy: 0.8660 - val_loss: 0.3383 - val_accuracy: 0.8564\n",
      "Epoch 159/200\n",
      "35/35 [==============================] - 8s 227ms/step - loss: 0.3401 - accuracy: 0.8669 - val_loss: 0.3289 - val_accuracy: 0.8709\n",
      "Epoch 160/200\n",
      "35/35 [==============================] - 8s 229ms/step - loss: 0.3332 - accuracy: 0.8715 - val_loss: 0.3334 - val_accuracy: 0.8600\n",
      "Epoch 161/200\n",
      "35/35 [==============================] - 8s 233ms/step - loss: 0.3335 - accuracy: 0.8688 - val_loss: 0.3284 - val_accuracy: 0.8673\n",
      "Epoch 162/200\n",
      "35/35 [==============================] - 8s 235ms/step - loss: 0.3391 - accuracy: 0.8692 - val_loss: 0.3311 - val_accuracy: 0.8655\n",
      "Epoch 163/200\n",
      "35/35 [==============================] - 8s 240ms/step - loss: 0.3325 - accuracy: 0.8647 - val_loss: 0.3279 - val_accuracy: 0.8673\n",
      "Epoch 164/200\n",
      "35/35 [==============================] - 8s 238ms/step - loss: 0.3359 - accuracy: 0.8733 - val_loss: 0.3297 - val_accuracy: 0.8636\n",
      "Epoch 165/200\n",
      "35/35 [==============================] - 8s 242ms/step - loss: 0.3247 - accuracy: 0.8738 - val_loss: 0.3281 - val_accuracy: 0.8636\n",
      "Epoch 166/200\n",
      "35/35 [==============================] - 8s 233ms/step - loss: 0.3349 - accuracy: 0.8669 - val_loss: 0.3268 - val_accuracy: 0.8691\n",
      "Epoch 167/200\n",
      "35/35 [==============================] - 8s 242ms/step - loss: 0.3386 - accuracy: 0.8678 - val_loss: 0.3384 - val_accuracy: 0.8509\n",
      "Epoch 168/200\n",
      "35/35 [==============================] - 8s 229ms/step - loss: 0.3278 - accuracy: 0.8706 - val_loss: 0.3276 - val_accuracy: 0.8636\n",
      "Epoch 169/200\n",
      "35/35 [==============================] - 8s 234ms/step - loss: 0.3291 - accuracy: 0.8724 - val_loss: 0.3285 - val_accuracy: 0.8600\n",
      "Epoch 170/200\n",
      "35/35 [==============================] - 8s 229ms/step - loss: 0.3328 - accuracy: 0.8701 - val_loss: 0.3366 - val_accuracy: 0.8491\n",
      "Epoch 171/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - 8s 235ms/step - loss: 0.3306 - accuracy: 0.8692 - val_loss: 0.3324 - val_accuracy: 0.8545\n",
      "Epoch 172/200\n",
      "35/35 [==============================] - 8s 235ms/step - loss: 0.3268 - accuracy: 0.8678 - val_loss: 0.3287 - val_accuracy: 0.8582\n",
      "Epoch 173/200\n",
      "35/35 [==============================] - 8s 233ms/step - loss: 0.3318 - accuracy: 0.8697 - val_loss: 0.3252 - val_accuracy: 0.8618\n",
      "Epoch 174/200\n",
      "35/35 [==============================] - 8s 232ms/step - loss: 0.3256 - accuracy: 0.8742 - val_loss: 0.3251 - val_accuracy: 0.8618\n",
      "Epoch 175/200\n",
      "35/35 [==============================] - 8s 232ms/step - loss: 0.3223 - accuracy: 0.8797 - val_loss: 0.3288 - val_accuracy: 0.8582\n",
      "Epoch 176/200\n",
      "35/35 [==============================] - 8s 238ms/step - loss: 0.3248 - accuracy: 0.8738 - val_loss: 0.3293 - val_accuracy: 0.8600\n",
      "Epoch 177/200\n",
      "35/35 [==============================] - 8s 235ms/step - loss: 0.3270 - accuracy: 0.8756 - val_loss: 0.3237 - val_accuracy: 0.8618\n",
      "Epoch 178/200\n",
      "35/35 [==============================] - 8s 242ms/step - loss: 0.3289 - accuracy: 0.8751 - val_loss: 0.3238 - val_accuracy: 0.8618\n",
      "Epoch 179/200\n",
      "35/35 [==============================] - 8s 238ms/step - loss: 0.3265 - accuracy: 0.8697 - val_loss: 0.3328 - val_accuracy: 0.8527\n",
      "Epoch 180/200\n",
      "35/35 [==============================] - 8s 242ms/step - loss: 0.3202 - accuracy: 0.8837 - val_loss: 0.3267 - val_accuracy: 0.8600\n",
      "Epoch 181/200\n",
      "35/35 [==============================] - 9s 245ms/step - loss: 0.3188 - accuracy: 0.8810 - val_loss: 0.3328 - val_accuracy: 0.8491\n",
      "Epoch 182/200\n",
      "35/35 [==============================] - 9s 244ms/step - loss: 0.3252 - accuracy: 0.8787 - val_loss: 0.3235 - val_accuracy: 0.8618\n",
      "Epoch 183/200\n",
      "35/35 [==============================] - 9s 244ms/step - loss: 0.3200 - accuracy: 0.8787 - val_loss: 0.3308 - val_accuracy: 0.8564\n",
      "Epoch 184/200\n",
      "35/35 [==============================] - 9s 262ms/step - loss: 0.3175 - accuracy: 0.8797 - val_loss: 0.3272 - val_accuracy: 0.8582\n",
      "Epoch 185/200\n",
      "35/35 [==============================] - 9s 271ms/step - loss: 0.3139 - accuracy: 0.8801 - val_loss: 0.3287 - val_accuracy: 0.8545\n",
      "Epoch 186/200\n",
      "35/35 [==============================] - 9s 252ms/step - loss: 0.3202 - accuracy: 0.8806 - val_loss: 0.3243 - val_accuracy: 0.8636\n",
      "Epoch 187/200\n",
      "35/35 [==============================] - 8s 238ms/step - loss: 0.3246 - accuracy: 0.8710 - val_loss: 0.3286 - val_accuracy: 0.8564\n",
      "Epoch 188/200\n",
      "35/35 [==============================] - 8s 240ms/step - loss: 0.3228 - accuracy: 0.8833 - val_loss: 0.3226 - val_accuracy: 0.8636\n",
      "Epoch 189/200\n",
      "35/35 [==============================] - 8s 237ms/step - loss: 0.3157 - accuracy: 0.8778 - val_loss: 0.3250 - val_accuracy: 0.8582\n",
      "Epoch 190/200\n",
      "35/35 [==============================] - 8s 234ms/step - loss: 0.3162 - accuracy: 0.8742 - val_loss: 0.3482 - val_accuracy: 0.8164\n",
      "Epoch 191/200\n",
      "35/35 [==============================] - 8s 242ms/step - loss: 0.3156 - accuracy: 0.8715 - val_loss: 0.3182 - val_accuracy: 0.8600\n",
      "Epoch 192/200\n",
      "35/35 [==============================] - 9s 252ms/step - loss: 0.3187 - accuracy: 0.8765 - val_loss: 0.3318 - val_accuracy: 0.8364\n",
      "Epoch 193/200\n",
      "35/35 [==============================] - 8s 237ms/step - loss: 0.3130 - accuracy: 0.8828 - val_loss: 0.3288 - val_accuracy: 0.8473\n",
      "Epoch 194/200\n",
      "35/35 [==============================] - 9s 244ms/step - loss: 0.3156 - accuracy: 0.8810 - val_loss: 0.3269 - val_accuracy: 0.8527\n",
      "Epoch 195/200\n",
      "35/35 [==============================] - 9s 263ms/step - loss: 0.3070 - accuracy: 0.8824 - val_loss: 0.3199 - val_accuracy: 0.8691\n",
      "Epoch 196/200\n",
      "35/35 [==============================] - 8s 241ms/step - loss: 0.3158 - accuracy: 0.8751 - val_loss: 0.3250 - val_accuracy: 0.8545\n",
      "Epoch 197/200\n",
      "35/35 [==============================] - 8s 242ms/step - loss: 0.3142 - accuracy: 0.8797 - val_loss: 0.3203 - val_accuracy: 0.8673\n",
      "Epoch 198/200\n",
      "35/35 [==============================] - 8s 227ms/step - loss: 0.3104 - accuracy: 0.8778 - val_loss: 0.3175 - val_accuracy: 0.8618\n",
      "Epoch 199/200\n",
      "35/35 [==============================] - 8s 241ms/step - loss: 0.3053 - accuracy: 0.8851 - val_loss: 0.3198 - val_accuracy: 0.8636\n",
      "Epoch 200/200\n",
      "35/35 [==============================] - 8s 234ms/step - loss: 0.3156 - accuracy: 0.8797 - val_loss: 0.3297 - val_accuracy: 0.8455\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x25f2f04ac40>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit(train_generator,\n",
    "                         epochs = 200,\n",
    "                         callbacks = [tensorboard_callback,es,mc,reduceLR],\n",
    "                         validation_data = validation_generator\n",
    "                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Overfitting -> Your training accuracy will be higher than the accuracy on the validation/test set\n",
    "\n",
    "#Overfitting indicates that your model is too complex for the problem that it is solving,\n",
    "#filters in the case of Convolutional Neural Networks, and layers in the case of overall Deep Learning Models\n",
    "\n",
    "#How do you know if your model is underfitting? Your model is underfitting if the accuracy on the validation set \n",
    "#is higher than the accuracy on the training set. Additionally, \n",
    "#if the whole model performs bad this is also called underfitting.\n",
    "\n",
    "#https://towardsdatascience.com/deep-learning-3-more-on-cnns-handling-overfitting-2bd5d99abe5d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-37e121fd743e2a74\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-37e121fd743e2a74\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir logs/fit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3 test the CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Model\n",
    "classifier.load_weights('best_cnn.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 150, 150, 8)       224       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 75, 75, 8)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 75, 75, 16)        1168      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 37, 37, 16)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 21904)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 32)                700960    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 702,385\n",
      "Trainable params: 702,385\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "classifier.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 688 images belonging to 2 classes.\n",
      "Test Loss 0.34699878096580505\n",
      "Test accuracy 0.882267415523529\n"
     ]
    }
   ],
   "source": [
    "test_set = datagen.flow_from_directory(parth_dir_test,\n",
    "                                        target_size= (150,150),\n",
    "                                        batch_size = 64,\n",
    "                                        seed = 11,\n",
    "                                        class_mode = 'binary',\n",
    "                                        shuffle=False)\n",
    "\n",
    "score = classifier.evaluate(test_set, verbose=0)\n",
    "\n",
    "print('Test Loss', score[0])\n",
    "print('Test accuracy', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\envs\\gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\sequential.py:455: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.87      0.88       344\n",
      "           1       0.87      0.89      0.88       344\n",
      "\n",
      "    accuracy                           0.88       688\n",
      "   macro avg       0.88      0.88      0.88       688\n",
      "weighted avg       0.88      0.88      0.88       688\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "yhat_classes = classifier.predict_classes(test_set, verbose=0)\n",
    "yhat_classes = yhat_classes[:, 0]\n",
    "\n",
    "print(classification_report(test_set.classes,yhat_classes))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
