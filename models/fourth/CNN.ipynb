{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural Network\n",
    "\n",
    "### Part 1 - Building the CNN\n",
    "\n",
    "#### Importing the Tensorflow libraries and packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor Flow Version: 2.6.0\n",
      "Keras Version: 2.6.0\n",
      "\n",
      "Python 3.8.13 | packaged by conda-forge | (default, Mar 25 2022, 05:59:45) [MSC v.1929 64 bit (AMD64)]\n",
      "Pandas 1.4.3\n",
      "Scikit-Learn 1.1.1\n",
      "GPU is available\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "import tensorflow.keras\n",
    "import pandas as pd\n",
    "import sklearn as sk\n",
    "import tensorflow as tf\n",
    "\n",
    "print(f\"Tensor Flow Version: {tf.__version__}\")\n",
    "print(f\"Keras Version: {tensorflow.keras.__version__}\")\n",
    "print()\n",
    "print(f\"Python {sys.version}\")\n",
    "print(f\"Pandas {pd.__version__}\")\n",
    "print(f\"Scikit-Learn {sk.__version__}\")\n",
    "gpu = len(tf.config.list_physical_devices('GPU'))>0\n",
    "print(\"GPU is\", \"available\" if gpu else \"NOT AVAILABLE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the TensorBoard notebook extension\n",
    "%load_ext tensorboard\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, GlobalAveragePooling2D\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = Sequential()\n",
    "\n",
    "#classes = 2\n",
    "\n",
    "#Kernels usually 1x1 | 3x3 | 5x5\n",
    "\n",
    "#Adding a convolutional layer\n",
    "classifier.add(Conv2D(8, (3, 3), input_shape = (150, 150, 3), padding='same', activation = 'relu'))\n",
    "classifier.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "#Adding a second convolutional layer\n",
    "classifier.add(Conv2D(16, (3, 3), padding='same', activation = 'relu'))\n",
    "classifier.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "#Flattening\n",
    "classifier.add(Flatten())\n",
    "\n",
    "#Full connection\n",
    "classifier.add(Dense(units = 32, activation = 'relu'))\n",
    "classifier.add(Dropout(0.30))\n",
    "classifier.add(Dense(units = 1, activation= 'sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's double check the model description:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 150, 150, 8)       224       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 75, 75, 8)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 75, 75, 16)        1168      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 37, 37, 16)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 21904)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 32)                700960    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 702,385\n",
      "Trainable params: 702,385\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "classifier.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "opt = Adam(learning_rate=0.00001)\n",
    "classifier.compile(optimizer = opt, loss = 'binary_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2 - Fitting the CNN to the images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2202 images belonging to 2 classes.\n",
      "Found 550 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "path_dir = '../../dataset/train'\n",
    "parth_dir_test = '../../dataset/test'\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "                    rescale=1./255,\n",
    "                    validation_split = 0.2)\n",
    "\n",
    "train_generator = datagen.flow_from_directory(\n",
    "    path_dir,\n",
    "    target_size=(150,150),\n",
    "    shuffle=True,\n",
    "    subset='training',\n",
    "    batch_size = 64,\n",
    "    seed = 11,\n",
    "    class_mode = 'binary'\n",
    ")\n",
    "validation_generator = datagen.flow_from_directory(\n",
    "    path_dir,\n",
    "    target_size=(150,150),\n",
    "    subset='validation',\n",
    "    batch_size = 64,\n",
    "    seed = 11,\n",
    "    class_mode = 'binary'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'nonviolence': 0, 'violence': 1}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_generator.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, TensorBoard\n",
    "import datetime\n",
    "\n",
    "#rm -rf /logs/\n",
    "\n",
    "es = EarlyStopping(monitor='val_loss', patience=30)\n",
    "mc = ModelCheckpoint('best_cnn.h5', monitor='val_loss', mode='min', save_best_only=True)\n",
    "reduceLR = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=20)\n",
    "\n",
    "# Create a TensorBoard callback\n",
    "log_dir = \"logs\\\\fit\\\\\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "35/35 [==============================] - 16s 318ms/step - loss: 0.6922 - accuracy: 0.5468 - val_loss: 0.6672 - val_accuracy: 0.6818\n",
      "Epoch 2/200\n",
      "35/35 [==============================] - 13s 363ms/step - loss: 0.6766 - accuracy: 0.5840 - val_loss: 0.6549 - val_accuracy: 0.6982\n",
      "Epoch 3/200\n",
      "35/35 [==============================] - 8s 242ms/step - loss: 0.6628 - accuracy: 0.6294 - val_loss: 0.6405 - val_accuracy: 0.7745\n",
      "Epoch 4/200\n",
      "35/35 [==============================] - 9s 252ms/step - loss: 0.6528 - accuracy: 0.6585 - val_loss: 0.6290 - val_accuracy: 0.7836\n",
      "Epoch 5/200\n",
      "35/35 [==============================] - 13s 369ms/step - loss: 0.6433 - accuracy: 0.6698 - val_loss: 0.6172 - val_accuracy: 0.7655\n",
      "Epoch 6/200\n",
      "35/35 [==============================] - 9s 243ms/step - loss: 0.6347 - accuracy: 0.6835 - val_loss: 0.6083 - val_accuracy: 0.7727\n",
      "Epoch 7/200\n",
      "35/35 [==============================] - 9s 247ms/step - loss: 0.6309 - accuracy: 0.6762 - val_loss: 0.6014 - val_accuracy: 0.7327\n",
      "Epoch 8/200\n",
      "35/35 [==============================] - 11s 312ms/step - loss: 0.6197 - accuracy: 0.6857 - val_loss: 0.5939 - val_accuracy: 0.7255\n",
      "Epoch 9/200\n",
      "35/35 [==============================] - 7s 211ms/step - loss: 0.6177 - accuracy: 0.6876 - val_loss: 0.5972 - val_accuracy: 0.6782\n",
      "Epoch 10/200\n",
      "35/35 [==============================] - 7s 210ms/step - loss: 0.6087 - accuracy: 0.6912 - val_loss: 0.5717 - val_accuracy: 0.7836\n",
      "Epoch 11/200\n",
      "35/35 [==============================] - 8s 236ms/step - loss: 0.5968 - accuracy: 0.7148 - val_loss: 0.5656 - val_accuracy: 0.7764\n",
      "Epoch 12/200\n",
      "35/35 [==============================] - 7s 209ms/step - loss: 0.5992 - accuracy: 0.6971 - val_loss: 0.5569 - val_accuracy: 0.8055\n",
      "Epoch 13/200\n",
      "35/35 [==============================] - 7s 210ms/step - loss: 0.6003 - accuracy: 0.6939 - val_loss: 0.5708 - val_accuracy: 0.7127\n",
      "Epoch 14/200\n",
      "35/35 [==============================] - 7s 208ms/step - loss: 0.5885 - accuracy: 0.7175 - val_loss: 0.5568 - val_accuracy: 0.7382\n",
      "Epoch 15/200\n",
      "35/35 [==============================] - 8s 218ms/step - loss: 0.5809 - accuracy: 0.7230 - val_loss: 0.5431 - val_accuracy: 0.7764\n",
      "Epoch 16/200\n",
      "35/35 [==============================] - 8s 240ms/step - loss: 0.5817 - accuracy: 0.7207 - val_loss: 0.5357 - val_accuracy: 0.7927\n",
      "Epoch 17/200\n",
      "35/35 [==============================] - 231s 7s/step - loss: 0.5834 - accuracy: 0.7148 - val_loss: 0.5393 - val_accuracy: 0.7709\n",
      "Epoch 18/200\n",
      "35/35 [==============================] - 8s 216ms/step - loss: 0.5770 - accuracy: 0.7257 - val_loss: 0.5338 - val_accuracy: 0.7818\n",
      "Epoch 19/200\n",
      "35/35 [==============================] - 7s 212ms/step - loss: 0.5657 - accuracy: 0.7275 - val_loss: 0.5201 - val_accuracy: 0.8109\n",
      "Epoch 20/200\n",
      "35/35 [==============================] - 644s 19s/step - loss: 0.5624 - accuracy: 0.7380 - val_loss: 0.5159 - val_accuracy: 0.8182\n",
      "Epoch 21/200\n",
      "35/35 [==============================] - 369s 10s/step - loss: 0.5645 - accuracy: 0.7280 - val_loss: 0.5162 - val_accuracy: 0.7909\n",
      "Epoch 22/200\n",
      "35/35 [==============================] - 8s 214ms/step - loss: 0.5577 - accuracy: 0.7416 - val_loss: 0.5187 - val_accuracy: 0.7727\n",
      "Epoch 23/200\n",
      "35/35 [==============================] - 7s 209ms/step - loss: 0.5555 - accuracy: 0.7389 - val_loss: 0.5036 - val_accuracy: 0.8218\n",
      "Epoch 24/200\n",
      "35/35 [==============================] - 7s 209ms/step - loss: 0.5540 - accuracy: 0.7425 - val_loss: 0.5047 - val_accuracy: 0.7982\n",
      "Epoch 25/200\n",
      "35/35 [==============================] - 8s 216ms/step - loss: 0.5498 - accuracy: 0.7452 - val_loss: 0.4974 - val_accuracy: 0.8127\n",
      "Epoch 26/200\n",
      "35/35 [==============================] - 8s 231ms/step - loss: 0.5459 - accuracy: 0.7361 - val_loss: 0.4930 - val_accuracy: 0.8218\n",
      "Epoch 27/200\n",
      "35/35 [==============================] - 7s 213ms/step - loss: 0.5377 - accuracy: 0.7516 - val_loss: 0.4971 - val_accuracy: 0.7891\n",
      "Epoch 28/200\n",
      "35/35 [==============================] - 7s 209ms/step - loss: 0.5371 - accuracy: 0.7493 - val_loss: 0.4863 - val_accuracy: 0.8291\n",
      "Epoch 29/200\n",
      "35/35 [==============================] - 7s 212ms/step - loss: 0.5318 - accuracy: 0.7661 - val_loss: 0.4811 - val_accuracy: 0.8473\n",
      "Epoch 30/200\n",
      "35/35 [==============================] - 7s 211ms/step - loss: 0.5291 - accuracy: 0.7629 - val_loss: 0.4916 - val_accuracy: 0.7927\n",
      "Epoch 31/200\n",
      "35/35 [==============================] - 7s 210ms/step - loss: 0.5298 - accuracy: 0.7625 - val_loss: 0.4823 - val_accuracy: 0.8109\n",
      "Epoch 32/200\n",
      "35/35 [==============================] - 7s 211ms/step - loss: 0.5194 - accuracy: 0.7757 - val_loss: 0.4699 - val_accuracy: 0.8618\n",
      "Epoch 33/200\n",
      "35/35 [==============================] - 9s 257ms/step - loss: 0.5154 - accuracy: 0.7679 - val_loss: 0.4654 - val_accuracy: 0.8600\n",
      "Epoch 34/200\n",
      "35/35 [==============================] - 10s 283ms/step - loss: 0.5121 - accuracy: 0.7784 - val_loss: 0.4633 - val_accuracy: 0.8527\n",
      "Epoch 35/200\n",
      "35/35 [==============================] - 7s 213ms/step - loss: 0.5081 - accuracy: 0.7784 - val_loss: 0.4587 - val_accuracy: 0.8618\n",
      "Epoch 36/200\n",
      "35/35 [==============================] - 8s 223ms/step - loss: 0.5044 - accuracy: 0.7825 - val_loss: 0.4595 - val_accuracy: 0.8382\n",
      "Epoch 37/200\n",
      "35/35 [==============================] - 7s 212ms/step - loss: 0.5021 - accuracy: 0.7884 - val_loss: 0.4532 - val_accuracy: 0.8709\n",
      "Epoch 38/200\n",
      "35/35 [==============================] - 8s 216ms/step - loss: 0.4946 - accuracy: 0.7925 - val_loss: 0.4483 - val_accuracy: 0.8764\n",
      "Epoch 39/200\n",
      "35/35 [==============================] - 7s 212ms/step - loss: 0.4953 - accuracy: 0.7979 - val_loss: 0.4479 - val_accuracy: 0.8527\n",
      "Epoch 40/200\n",
      "35/35 [==============================] - 8s 218ms/step - loss: 0.4928 - accuracy: 0.8015 - val_loss: 0.4437 - val_accuracy: 0.8727\n",
      "Epoch 41/200\n",
      "35/35 [==============================] - 7s 213ms/step - loss: 0.4954 - accuracy: 0.7888 - val_loss: 0.4398 - val_accuracy: 0.8764\n",
      "Epoch 42/200\n",
      "35/35 [==============================] - 7s 210ms/step - loss: 0.4815 - accuracy: 0.7970 - val_loss: 0.4365 - val_accuracy: 0.8727\n",
      "Epoch 43/200\n",
      "35/35 [==============================] - 7s 211ms/step - loss: 0.4782 - accuracy: 0.8006 - val_loss: 0.4342 - val_accuracy: 0.8618\n",
      "Epoch 44/200\n",
      "35/35 [==============================] - 7s 213ms/step - loss: 0.4751 - accuracy: 0.8038 - val_loss: 0.4323 - val_accuracy: 0.8636\n",
      "Epoch 45/200\n",
      "35/35 [==============================] - 7s 208ms/step - loss: 0.4666 - accuracy: 0.8134 - val_loss: 0.4250 - val_accuracy: 0.8727\n",
      "Epoch 46/200\n",
      "35/35 [==============================] - 7s 210ms/step - loss: 0.4700 - accuracy: 0.8074 - val_loss: 0.4227 - val_accuracy: 0.8709\n",
      "Epoch 47/200\n",
      "35/35 [==============================] - 7s 208ms/step - loss: 0.4626 - accuracy: 0.8079 - val_loss: 0.4195 - val_accuracy: 0.8691\n",
      "Epoch 48/200\n",
      "35/35 [==============================] - 7s 208ms/step - loss: 0.4635 - accuracy: 0.8134 - val_loss: 0.4182 - val_accuracy: 0.8655\n",
      "Epoch 49/200\n",
      "35/35 [==============================] - 7s 209ms/step - loss: 0.4655 - accuracy: 0.8061 - val_loss: 0.4156 - val_accuracy: 0.8655\n",
      "Epoch 50/200\n",
      "35/35 [==============================] - 7s 208ms/step - loss: 0.4641 - accuracy: 0.8038 - val_loss: 0.4213 - val_accuracy: 0.8345\n",
      "Epoch 51/200\n",
      "35/35 [==============================] - 7s 208ms/step - loss: 0.4532 - accuracy: 0.8115 - val_loss: 0.4125 - val_accuracy: 0.8636\n",
      "Epoch 52/200\n",
      "35/35 [==============================] - 7s 216ms/step - loss: 0.4528 - accuracy: 0.8143 - val_loss: 0.4093 - val_accuracy: 0.8655\n",
      "Epoch 53/200\n",
      "35/35 [==============================] - 7s 212ms/step - loss: 0.4532 - accuracy: 0.8170 - val_loss: 0.4083 - val_accuracy: 0.8691\n",
      "Epoch 54/200\n",
      "35/35 [==============================] - 8s 217ms/step - loss: 0.4539 - accuracy: 0.8161 - val_loss: 0.4060 - val_accuracy: 0.8691\n",
      "Epoch 55/200\n",
      "35/35 [==============================] - 8s 227ms/step - loss: 0.4526 - accuracy: 0.8170 - val_loss: 0.4053 - val_accuracy: 0.8691\n",
      "Epoch 56/200\n",
      "35/35 [==============================] - 9s 245ms/step - loss: 0.4460 - accuracy: 0.8215 - val_loss: 0.4024 - val_accuracy: 0.8655\n",
      "Epoch 57/200\n",
      "35/35 [==============================] - 8s 219ms/step - loss: 0.4444 - accuracy: 0.8220 - val_loss: 0.4026 - val_accuracy: 0.8564\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/200\n",
      "35/35 [==============================] - 7s 214ms/step - loss: 0.4485 - accuracy: 0.8115 - val_loss: 0.4005 - val_accuracy: 0.8636\n",
      "Epoch 59/200\n",
      "35/35 [==============================] - 13s 378ms/step - loss: 0.4435 - accuracy: 0.8197 - val_loss: 0.3967 - val_accuracy: 0.8673\n",
      "Epoch 60/200\n",
      "35/35 [==============================] - 16s 462ms/step - loss: 0.4396 - accuracy: 0.8220 - val_loss: 0.3976 - val_accuracy: 0.8636\n",
      "Epoch 61/200\n",
      "35/35 [==============================] - 8s 227ms/step - loss: 0.4421 - accuracy: 0.8152 - val_loss: 0.3972 - val_accuracy: 0.8673\n",
      "Epoch 62/200\n",
      "35/35 [==============================] - 8s 216ms/step - loss: 0.4364 - accuracy: 0.8243 - val_loss: 0.3943 - val_accuracy: 0.8618\n",
      "Epoch 63/200\n",
      "35/35 [==============================] - 8s 218ms/step - loss: 0.4348 - accuracy: 0.8147 - val_loss: 0.3915 - val_accuracy: 0.8673\n",
      "Epoch 64/200\n",
      "35/35 [==============================] - 8s 216ms/step - loss: 0.4372 - accuracy: 0.8288 - val_loss: 0.3950 - val_accuracy: 0.8527\n",
      "Epoch 65/200\n",
      "35/35 [==============================] - 8s 216ms/step - loss: 0.4282 - accuracy: 0.8274 - val_loss: 0.3874 - val_accuracy: 0.8727\n",
      "Epoch 66/200\n",
      "35/35 [==============================] - 8s 224ms/step - loss: 0.4246 - accuracy: 0.8361 - val_loss: 0.3944 - val_accuracy: 0.8418\n",
      "Epoch 67/200\n",
      "35/35 [==============================] - 8s 226ms/step - loss: 0.4299 - accuracy: 0.8279 - val_loss: 0.3860 - val_accuracy: 0.8691\n",
      "Epoch 68/200\n",
      "35/35 [==============================] - 9s 255ms/step - loss: 0.4275 - accuracy: 0.8283 - val_loss: 0.3868 - val_accuracy: 0.8673\n",
      "Epoch 69/200\n",
      "35/35 [==============================] - 9s 258ms/step - loss: 0.4265 - accuracy: 0.8279 - val_loss: 0.3886 - val_accuracy: 0.8545\n",
      "Epoch 70/200\n",
      "35/35 [==============================] - 8s 239ms/step - loss: 0.4242 - accuracy: 0.8279 - val_loss: 0.3835 - val_accuracy: 0.8655\n",
      "Epoch 71/200\n",
      "35/35 [==============================] - 9s 212ms/step - loss: 0.4240 - accuracy: 0.8351 - val_loss: 0.3922 - val_accuracy: 0.8309\n",
      "Epoch 72/200\n",
      "35/35 [==============================] - 7s 212ms/step - loss: 0.4211 - accuracy: 0.8238 - val_loss: 0.3824 - val_accuracy: 0.8673\n",
      "Epoch 73/200\n",
      "35/35 [==============================] - 7s 212ms/step - loss: 0.4214 - accuracy: 0.8252 - val_loss: 0.3804 - val_accuracy: 0.8691\n",
      "Epoch 74/200\n",
      "35/35 [==============================] - 8s 222ms/step - loss: 0.4137 - accuracy: 0.8356 - val_loss: 0.3847 - val_accuracy: 0.8473\n",
      "Epoch 75/200\n",
      "35/35 [==============================] - 7s 210ms/step - loss: 0.4137 - accuracy: 0.8397 - val_loss: 0.3877 - val_accuracy: 0.8327\n",
      "Epoch 76/200\n",
      "35/35 [==============================] - 7s 213ms/step - loss: 0.4180 - accuracy: 0.8315 - val_loss: 0.3809 - val_accuracy: 0.8491\n",
      "Epoch 77/200\n",
      "35/35 [==============================] - 8s 217ms/step - loss: 0.4085 - accuracy: 0.8415 - val_loss: 0.3764 - val_accuracy: 0.8673\n",
      "Epoch 78/200\n",
      "35/35 [==============================] - 8s 229ms/step - loss: 0.4147 - accuracy: 0.8379 - val_loss: 0.3907 - val_accuracy: 0.8200\n",
      "Epoch 79/200\n",
      "35/35 [==============================] - 9s 246ms/step - loss: 0.4117 - accuracy: 0.8315 - val_loss: 0.3805 - val_accuracy: 0.8527\n",
      "Epoch 80/200\n",
      "35/35 [==============================] - 10s 284ms/step - loss: 0.4122 - accuracy: 0.8311 - val_loss: 0.3749 - val_accuracy: 0.8709\n",
      "Epoch 81/200\n",
      "35/35 [==============================] - 8s 223ms/step - loss: 0.4077 - accuracy: 0.8420 - val_loss: 0.3843 - val_accuracy: 0.8364\n",
      "Epoch 82/200\n",
      "35/35 [==============================] - 8s 239ms/step - loss: 0.4143 - accuracy: 0.8361 - val_loss: 0.3757 - val_accuracy: 0.8545\n",
      "Epoch 83/200\n",
      "35/35 [==============================] - 7s 215ms/step - loss: 0.4030 - accuracy: 0.8365 - val_loss: 0.3724 - val_accuracy: 0.8673\n",
      "Epoch 84/200\n",
      "35/35 [==============================] - 7s 214ms/step - loss: 0.4016 - accuracy: 0.8397 - val_loss: 0.3735 - val_accuracy: 0.8509\n",
      "Epoch 85/200\n",
      "35/35 [==============================] - 8s 218ms/step - loss: 0.4036 - accuracy: 0.8311 - val_loss: 0.3728 - val_accuracy: 0.8509\n",
      "Epoch 86/200\n",
      "35/35 [==============================] - 16s 459ms/step - loss: 0.3994 - accuracy: 0.8488 - val_loss: 0.3737 - val_accuracy: 0.8509\n",
      "Epoch 87/200\n",
      "35/35 [==============================] - 9s 255ms/step - loss: 0.3995 - accuracy: 0.8442 - val_loss: 0.3697 - val_accuracy: 0.8582\n",
      "Epoch 88/200\n",
      "35/35 [==============================] - 7s 213ms/step - loss: 0.4023 - accuracy: 0.8383 - val_loss: 0.3994 - val_accuracy: 0.8055\n",
      "Epoch 89/200\n",
      "35/35 [==============================] - 7s 212ms/step - loss: 0.4063 - accuracy: 0.8356 - val_loss: 0.3687 - val_accuracy: 0.8673\n",
      "Epoch 90/200\n",
      "35/35 [==============================] - 7s 212ms/step - loss: 0.4007 - accuracy: 0.8420 - val_loss: 0.3800 - val_accuracy: 0.8345\n",
      "Epoch 91/200\n",
      "35/35 [==============================] - 7s 213ms/step - loss: 0.3922 - accuracy: 0.8488 - val_loss: 0.3681 - val_accuracy: 0.8636\n",
      "Epoch 92/200\n",
      "35/35 [==============================] - 7s 211ms/step - loss: 0.3923 - accuracy: 0.8438 - val_loss: 0.3660 - val_accuracy: 0.8527\n",
      "Epoch 93/200\n",
      "35/35 [==============================] - 7s 213ms/step - loss: 0.3903 - accuracy: 0.8442 - val_loss: 0.3726 - val_accuracy: 0.8636\n",
      "Epoch 94/200\n",
      "35/35 [==============================] - 7s 213ms/step - loss: 0.3952 - accuracy: 0.8474 - val_loss: 0.3666 - val_accuracy: 0.8527\n",
      "Epoch 95/200\n",
      "35/35 [==============================] - 7s 211ms/step - loss: 0.3905 - accuracy: 0.8479 - val_loss: 0.3649 - val_accuracy: 0.8636\n",
      "Epoch 96/200\n",
      "35/35 [==============================] - 7s 211ms/step - loss: 0.3932 - accuracy: 0.8447 - val_loss: 0.3654 - val_accuracy: 0.8491\n",
      "Epoch 97/200\n",
      "35/35 [==============================] - 7s 213ms/step - loss: 0.3862 - accuracy: 0.8488 - val_loss: 0.3627 - val_accuracy: 0.8673\n",
      "Epoch 98/200\n",
      "35/35 [==============================] - 7s 211ms/step - loss: 0.3891 - accuracy: 0.8415 - val_loss: 0.3633 - val_accuracy: 0.8582\n",
      "Epoch 99/200\n",
      "35/35 [==============================] - 7s 212ms/step - loss: 0.3863 - accuracy: 0.8529 - val_loss: 0.3624 - val_accuracy: 0.8691\n",
      "Epoch 100/200\n",
      "35/35 [==============================] - 7s 213ms/step - loss: 0.3869 - accuracy: 0.8515 - val_loss: 0.3678 - val_accuracy: 0.8473\n",
      "Epoch 101/200\n",
      "35/35 [==============================] - 7s 211ms/step - loss: 0.3844 - accuracy: 0.8506 - val_loss: 0.3646 - val_accuracy: 0.8473\n",
      "Epoch 102/200\n",
      "35/35 [==============================] - 7s 213ms/step - loss: 0.3834 - accuracy: 0.8488 - val_loss: 0.3608 - val_accuracy: 0.8709\n",
      "Epoch 103/200\n",
      "35/35 [==============================] - 7s 213ms/step - loss: 0.3783 - accuracy: 0.8529 - val_loss: 0.3627 - val_accuracy: 0.8527\n",
      "Epoch 104/200\n",
      "35/35 [==============================] - 15s 432ms/step - loss: 0.3840 - accuracy: 0.8515 - val_loss: 0.3655 - val_accuracy: 0.8455\n",
      "Epoch 105/200\n",
      "35/35 [==============================] - 8s 225ms/step - loss: 0.3839 - accuracy: 0.8520 - val_loss: 0.3634 - val_accuracy: 0.8473\n",
      "Epoch 106/200\n",
      "35/35 [==============================] - 8s 221ms/step - loss: 0.3821 - accuracy: 0.8547 - val_loss: 0.3626 - val_accuracy: 0.8473\n",
      "Epoch 107/200\n",
      "35/35 [==============================] - 9s 230ms/step - loss: 0.3792 - accuracy: 0.8569 - val_loss: 0.3658 - val_accuracy: 0.8455\n",
      "Epoch 108/200\n",
      "35/35 [==============================] - 8s 215ms/step - loss: 0.3766 - accuracy: 0.8501 - val_loss: 0.3588 - val_accuracy: 0.8564\n",
      "Epoch 109/200\n",
      "35/35 [==============================] - 9s 252ms/step - loss: 0.3819 - accuracy: 0.8501 - val_loss: 0.3707 - val_accuracy: 0.8273\n",
      "Epoch 110/200\n",
      "35/35 [==============================] - 8s 240ms/step - loss: 0.3717 - accuracy: 0.8538 - val_loss: 0.3592 - val_accuracy: 0.8455\n",
      "Epoch 111/200\n",
      "35/35 [==============================] - 8s 215ms/step - loss: 0.3713 - accuracy: 0.8492 - val_loss: 0.3607 - val_accuracy: 0.8473\n",
      "Epoch 112/200\n",
      "35/35 [==============================] - 8s 217ms/step - loss: 0.3735 - accuracy: 0.8588 - val_loss: 0.3579 - val_accuracy: 0.8455\n",
      "Epoch 113/200\n",
      "35/35 [==============================] - 7s 213ms/step - loss: 0.3726 - accuracy: 0.8547 - val_loss: 0.3591 - val_accuracy: 0.8455\n",
      "Epoch 114/200\n",
      "35/35 [==============================] - 8s 223ms/step - loss: 0.3759 - accuracy: 0.8479 - val_loss: 0.3566 - val_accuracy: 0.8655\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 115/200\n",
      "35/35 [==============================] - 8s 210ms/step - loss: 0.3710 - accuracy: 0.8592 - val_loss: 0.3532 - val_accuracy: 0.8636\n",
      "Epoch 116/200\n",
      "35/35 [==============================] - 9s 259ms/step - loss: 0.3673 - accuracy: 0.8606 - val_loss: 0.3528 - val_accuracy: 0.8564\n",
      "Epoch 117/200\n",
      "35/35 [==============================] - 11s 321ms/step - loss: 0.3643 - accuracy: 0.8588 - val_loss: 0.3623 - val_accuracy: 0.8400\n",
      "Epoch 118/200\n",
      "35/35 [==============================] - 8s 218ms/step - loss: 0.3657 - accuracy: 0.8601 - val_loss: 0.3588 - val_accuracy: 0.8455\n",
      "Epoch 119/200\n",
      "35/35 [==============================] - 8s 223ms/step - loss: 0.3617 - accuracy: 0.8674 - val_loss: 0.3527 - val_accuracy: 0.8564\n",
      "Epoch 120/200\n",
      "35/35 [==============================] - 8s 235ms/step - loss: 0.3661 - accuracy: 0.8551 - val_loss: 0.3527 - val_accuracy: 0.8509\n",
      "Epoch 121/200\n",
      "35/35 [==============================] - 9s 248ms/step - loss: 0.3598 - accuracy: 0.8579 - val_loss: 0.3491 - val_accuracy: 0.8582\n",
      "Epoch 122/200\n",
      "35/35 [==============================] - 9s 259ms/step - loss: 0.3667 - accuracy: 0.8588 - val_loss: 0.3615 - val_accuracy: 0.8364\n",
      "Epoch 123/200\n",
      "35/35 [==============================] - 31s 912ms/step - loss: 0.3666 - accuracy: 0.8606 - val_loss: 0.3513 - val_accuracy: 0.8545\n",
      "Epoch 124/200\n",
      "35/35 [==============================] - 7s 211ms/step - loss: 0.3656 - accuracy: 0.8615 - val_loss: 0.3504 - val_accuracy: 0.8673\n",
      "Epoch 125/200\n",
      "35/35 [==============================] - 8s 223ms/step - loss: 0.3664 - accuracy: 0.8547 - val_loss: 0.3491 - val_accuracy: 0.8545\n",
      "Epoch 126/200\n",
      "35/35 [==============================] - 7s 212ms/step - loss: 0.3586 - accuracy: 0.8597 - val_loss: 0.3656 - val_accuracy: 0.8273\n",
      "Epoch 127/200\n",
      "35/35 [==============================] - 7s 211ms/step - loss: 0.3600 - accuracy: 0.8660 - val_loss: 0.3463 - val_accuracy: 0.8545\n",
      "Epoch 128/200\n",
      "35/35 [==============================] - 10s 292ms/step - loss: 0.3553 - accuracy: 0.8656 - val_loss: 0.3544 - val_accuracy: 0.8455\n",
      "Epoch 129/200\n",
      "35/35 [==============================] - 8s 229ms/step - loss: 0.3661 - accuracy: 0.8615 - val_loss: 0.3527 - val_accuracy: 0.8491\n",
      "Epoch 130/200\n",
      "35/35 [==============================] - 9s 249ms/step - loss: 0.3584 - accuracy: 0.8665 - val_loss: 0.3546 - val_accuracy: 0.8455\n",
      "Epoch 131/200\n",
      "35/35 [==============================] - 8s 230ms/step - loss: 0.3573 - accuracy: 0.8629 - val_loss: 0.3436 - val_accuracy: 0.8618\n",
      "Epoch 132/200\n",
      "35/35 [==============================] - 12s 333ms/step - loss: 0.3548 - accuracy: 0.8656 - val_loss: 0.3514 - val_accuracy: 0.8473\n",
      "Epoch 133/200\n",
      "35/35 [==============================] - 8s 232ms/step - loss: 0.3534 - accuracy: 0.8619 - val_loss: 0.3439 - val_accuracy: 0.8582\n",
      "Epoch 134/200\n",
      "35/35 [==============================] - 8s 220ms/step - loss: 0.3500 - accuracy: 0.8642 - val_loss: 0.3485 - val_accuracy: 0.8473\n",
      "Epoch 135/200\n",
      "35/35 [==============================] - 8s 232ms/step - loss: 0.3504 - accuracy: 0.8660 - val_loss: 0.3426 - val_accuracy: 0.8582\n",
      "Epoch 136/200\n",
      "35/35 [==============================] - 8s 227ms/step - loss: 0.3575 - accuracy: 0.8629 - val_loss: 0.3480 - val_accuracy: 0.8527\n",
      "Epoch 137/200\n",
      "35/35 [==============================] - 11s 307ms/step - loss: 0.3516 - accuracy: 0.8606 - val_loss: 0.3423 - val_accuracy: 0.8527\n",
      "Epoch 138/200\n",
      "35/35 [==============================] - 8s 216ms/step - loss: 0.3584 - accuracy: 0.8610 - val_loss: 0.3483 - val_accuracy: 0.8509\n",
      "Epoch 139/200\n",
      "35/35 [==============================] - 8s 223ms/step - loss: 0.3468 - accuracy: 0.8724 - val_loss: 0.3389 - val_accuracy: 0.8655\n",
      "Epoch 140/200\n",
      "35/35 [==============================] - 8s 218ms/step - loss: 0.3510 - accuracy: 0.8674 - val_loss: 0.3451 - val_accuracy: 0.8509\n",
      "Epoch 141/200\n",
      "35/35 [==============================] - 12s 334ms/step - loss: 0.3483 - accuracy: 0.8588 - val_loss: 0.3473 - val_accuracy: 0.8473\n",
      "Epoch 142/200\n",
      "35/35 [==============================] - 8s 239ms/step - loss: 0.3476 - accuracy: 0.8674 - val_loss: 0.3369 - val_accuracy: 0.8600\n",
      "Epoch 143/200\n",
      "35/35 [==============================] - 8s 219ms/step - loss: 0.3444 - accuracy: 0.8674 - val_loss: 0.3401 - val_accuracy: 0.8582\n",
      "Epoch 144/200\n",
      "35/35 [==============================] - 8s 220ms/step - loss: 0.3449 - accuracy: 0.8728 - val_loss: 0.3470 - val_accuracy: 0.8455\n",
      "Epoch 145/200\n",
      "35/35 [==============================] - 7s 213ms/step - loss: 0.3396 - accuracy: 0.8647 - val_loss: 0.3413 - val_accuracy: 0.8527\n",
      "Epoch 146/200\n",
      "35/35 [==============================] - 8s 216ms/step - loss: 0.3441 - accuracy: 0.8697 - val_loss: 0.3404 - val_accuracy: 0.8527\n",
      "Epoch 147/200\n",
      "35/35 [==============================] - 7s 215ms/step - loss: 0.3449 - accuracy: 0.8638 - val_loss: 0.3364 - val_accuracy: 0.8582\n",
      "Epoch 148/200\n",
      "35/35 [==============================] - 7s 212ms/step - loss: 0.3402 - accuracy: 0.8651 - val_loss: 0.3401 - val_accuracy: 0.8509\n",
      "Epoch 149/200\n",
      "35/35 [==============================] - 8s 235ms/step - loss: 0.3352 - accuracy: 0.8697 - val_loss: 0.3334 - val_accuracy: 0.8582\n",
      "Epoch 150/200\n",
      "35/35 [==============================] - 8s 223ms/step - loss: 0.3426 - accuracy: 0.8629 - val_loss: 0.3353 - val_accuracy: 0.8600\n",
      "Epoch 151/200\n",
      "35/35 [==============================] - 8s 220ms/step - loss: 0.3427 - accuracy: 0.8747 - val_loss: 0.3394 - val_accuracy: 0.8509\n",
      "Epoch 152/200\n",
      "35/35 [==============================] - 8s 231ms/step - loss: 0.3396 - accuracy: 0.8724 - val_loss: 0.3352 - val_accuracy: 0.8564\n",
      "Epoch 153/200\n",
      "35/35 [==============================] - 10s 299ms/step - loss: 0.3389 - accuracy: 0.8747 - val_loss: 0.3334 - val_accuracy: 0.8545\n",
      "Epoch 154/200\n",
      "35/35 [==============================] - 8s 216ms/step - loss: 0.3411 - accuracy: 0.8747 - val_loss: 0.3335 - val_accuracy: 0.8545\n",
      "Epoch 155/200\n",
      "35/35 [==============================] - 7s 213ms/step - loss: 0.3341 - accuracy: 0.8678 - val_loss: 0.3320 - val_accuracy: 0.8564\n",
      "Epoch 156/200\n",
      "35/35 [==============================] - 8s 218ms/step - loss: 0.3362 - accuracy: 0.8760 - val_loss: 0.3450 - val_accuracy: 0.8436\n",
      "Epoch 157/200\n",
      "35/35 [==============================] - 8s 224ms/step - loss: 0.3393 - accuracy: 0.8778 - val_loss: 0.3491 - val_accuracy: 0.8345\n",
      "Epoch 158/200\n",
      "35/35 [==============================] - 7s 213ms/step - loss: 0.3384 - accuracy: 0.8728 - val_loss: 0.3315 - val_accuracy: 0.8745\n",
      "Epoch 159/200\n",
      "35/35 [==============================] - 23s 658ms/step - loss: 0.3377 - accuracy: 0.8710 - val_loss: 0.3449 - val_accuracy: 0.8345\n",
      "Epoch 160/200\n",
      "35/35 [==============================] - 7s 217ms/step - loss: 0.3306 - accuracy: 0.8751 - val_loss: 0.3403 - val_accuracy: 0.8455\n",
      "Epoch 161/200\n",
      "35/35 [==============================] - 8s 216ms/step - loss: 0.3341 - accuracy: 0.8733 - val_loss: 0.3279 - val_accuracy: 0.8618\n",
      "Epoch 162/200\n",
      "35/35 [==============================] - 8s 217ms/step - loss: 0.3296 - accuracy: 0.8751 - val_loss: 0.3412 - val_accuracy: 0.8436\n",
      "Epoch 163/200\n",
      "35/35 [==============================] - 8s 217ms/step - loss: 0.3277 - accuracy: 0.8742 - val_loss: 0.3275 - val_accuracy: 0.8600\n",
      "Epoch 164/200\n",
      "35/35 [==============================] - 7s 214ms/step - loss: 0.3313 - accuracy: 0.8710 - val_loss: 0.3332 - val_accuracy: 0.8545\n",
      "Epoch 165/200\n",
      "35/35 [==============================] - 8s 223ms/step - loss: 0.3245 - accuracy: 0.8774 - val_loss: 0.3268 - val_accuracy: 0.8564\n",
      "Epoch 166/200\n",
      "35/35 [==============================] - 7s 214ms/step - loss: 0.3322 - accuracy: 0.8747 - val_loss: 0.3303 - val_accuracy: 0.8545\n",
      "Epoch 167/200\n",
      "35/35 [==============================] - 8s 233ms/step - loss: 0.3263 - accuracy: 0.8810 - val_loss: 0.3238 - val_accuracy: 0.8636\n",
      "Epoch 168/200\n",
      "35/35 [==============================] - 8s 217ms/step - loss: 0.3237 - accuracy: 0.8742 - val_loss: 0.3296 - val_accuracy: 0.8545\n",
      "Epoch 169/200\n",
      "35/35 [==============================] - 8s 219ms/step - loss: 0.3234 - accuracy: 0.8769 - val_loss: 0.3382 - val_accuracy: 0.8418\n",
      "Epoch 170/200\n",
      "35/35 [==============================] - 7s 213ms/step - loss: 0.3229 - accuracy: 0.8833 - val_loss: 0.3288 - val_accuracy: 0.8564\n",
      "Epoch 171/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - 8s 215ms/step - loss: 0.3178 - accuracy: 0.8819 - val_loss: 0.3258 - val_accuracy: 0.8582\n",
      "Epoch 172/200\n",
      "35/35 [==============================] - 7s 212ms/step - loss: 0.3342 - accuracy: 0.8710 - val_loss: 0.3400 - val_accuracy: 0.8418\n",
      "Epoch 173/200\n",
      "35/35 [==============================] - 7s 210ms/step - loss: 0.3252 - accuracy: 0.8760 - val_loss: 0.3257 - val_accuracy: 0.8618\n",
      "Epoch 174/200\n",
      "35/35 [==============================] - 7s 217ms/step - loss: 0.3271 - accuracy: 0.8710 - val_loss: 0.3281 - val_accuracy: 0.8582\n",
      "Epoch 175/200\n",
      "35/35 [==============================] - 8s 225ms/step - loss: 0.3242 - accuracy: 0.8747 - val_loss: 0.3325 - val_accuracy: 0.8491\n",
      "Epoch 176/200\n",
      "35/35 [==============================] - 8s 227ms/step - loss: 0.3163 - accuracy: 0.8828 - val_loss: 0.3234 - val_accuracy: 0.8564\n",
      "Epoch 177/200\n",
      "35/35 [==============================] - 19s 543ms/step - loss: 0.3252 - accuracy: 0.8738 - val_loss: 0.3244 - val_accuracy: 0.8600\n",
      "Epoch 178/200\n",
      "35/35 [==============================] - 8s 231ms/step - loss: 0.3165 - accuracy: 0.8860 - val_loss: 0.3241 - val_accuracy: 0.8582\n",
      "Epoch 179/200\n",
      "35/35 [==============================] - 8s 223ms/step - loss: 0.3207 - accuracy: 0.8792 - val_loss: 0.3442 - val_accuracy: 0.8291\n",
      "Epoch 180/200\n",
      "35/35 [==============================] - 8s 223ms/step - loss: 0.3164 - accuracy: 0.8792 - val_loss: 0.3183 - val_accuracy: 0.8691\n",
      "Epoch 181/200\n",
      "35/35 [==============================] - 8s 228ms/step - loss: 0.3198 - accuracy: 0.8751 - val_loss: 0.3316 - val_accuracy: 0.8473\n",
      "Epoch 182/200\n",
      "35/35 [==============================] - 8s 211ms/step - loss: 0.3198 - accuracy: 0.8769 - val_loss: 0.3276 - val_accuracy: 0.8473\n",
      "Epoch 183/200\n",
      "35/35 [==============================] - 7s 212ms/step - loss: 0.3167 - accuracy: 0.8765 - val_loss: 0.3229 - val_accuracy: 0.8564\n",
      "Epoch 184/200\n",
      "35/35 [==============================] - 8s 218ms/step - loss: 0.3141 - accuracy: 0.8760 - val_loss: 0.3215 - val_accuracy: 0.8582\n",
      "Epoch 185/200\n",
      "35/35 [==============================] - 8s 218ms/step - loss: 0.3113 - accuracy: 0.8837 - val_loss: 0.3168 - val_accuracy: 0.8636\n",
      "Epoch 186/200\n",
      "35/35 [==============================] - 255s 7s/step - loss: 0.3212 - accuracy: 0.8719 - val_loss: 0.3533 - val_accuracy: 0.8236\n",
      "Epoch 187/200\n",
      "35/35 [==============================] - 25s 556ms/step - loss: 0.3185 - accuracy: 0.8774 - val_loss: 0.3214 - val_accuracy: 0.8600\n",
      "Epoch 188/200\n",
      "35/35 [==============================] - 16s 441ms/step - loss: 0.3091 - accuracy: 0.8819 - val_loss: 0.3153 - val_accuracy: 0.8618\n",
      "Epoch 189/200\n",
      "35/35 [==============================] - 9s 249ms/step - loss: 0.3141 - accuracy: 0.8815 - val_loss: 0.3389 - val_accuracy: 0.8309\n",
      "Epoch 190/200\n",
      "35/35 [==============================] - 20s 584ms/step - loss: 0.3150 - accuracy: 0.8842 - val_loss: 0.3353 - val_accuracy: 0.8345\n",
      "Epoch 191/200\n",
      "35/35 [==============================] - 8s 219ms/step - loss: 0.3158 - accuracy: 0.8819 - val_loss: 0.3191 - val_accuracy: 0.8600\n",
      "Epoch 192/200\n",
      "35/35 [==============================] - 7s 210ms/step - loss: 0.3085 - accuracy: 0.8792 - val_loss: 0.3150 - val_accuracy: 0.8636\n",
      "Epoch 193/200\n",
      "35/35 [==============================] - 8s 235ms/step - loss: 0.3100 - accuracy: 0.8856 - val_loss: 0.3301 - val_accuracy: 0.8436\n",
      "Epoch 194/200\n",
      "35/35 [==============================] - 8s 215ms/step - loss: 0.3059 - accuracy: 0.8896 - val_loss: 0.3120 - val_accuracy: 0.8836\n",
      "Epoch 195/200\n",
      "35/35 [==============================] - 7s 214ms/step - loss: 0.3033 - accuracy: 0.8851 - val_loss: 0.3124 - val_accuracy: 0.8655\n",
      "Epoch 196/200\n",
      "35/35 [==============================] - 7s 213ms/step - loss: 0.3081 - accuracy: 0.8760 - val_loss: 0.3170 - val_accuracy: 0.8636\n",
      "Epoch 197/200\n",
      "35/35 [==============================] - 7s 211ms/step - loss: 0.3130 - accuracy: 0.8819 - val_loss: 0.3096 - val_accuracy: 0.8709\n",
      "Epoch 198/200\n",
      "35/35 [==============================] - 7s 216ms/step - loss: 0.3022 - accuracy: 0.8887 - val_loss: 0.3085 - val_accuracy: 0.8709\n",
      "Epoch 199/200\n",
      "35/35 [==============================] - 7s 214ms/step - loss: 0.3037 - accuracy: 0.8837 - val_loss: 0.3108 - val_accuracy: 0.8655\n",
      "Epoch 200/200\n",
      "35/35 [==============================] - 7s 212ms/step - loss: 0.3049 - accuracy: 0.8828 - val_loss: 0.3168 - val_accuracy: 0.8600\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x17c3ce9db50>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit(train_generator,\n",
    "                         epochs = 200,\n",
    "                         callbacks = [tensorboard_callback,es,mc,reduceLR],\n",
    "                         validation_data = validation_generator\n",
    "                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Overfitting -> Your training accuracy will be higher than the accuracy on the validation/test set\n",
    "\n",
    "#Overfitting indicates that your model is too complex for the problem that it is solving,\n",
    "#filters in the case of Convolutional Neural Networks, and layers in the case of overall Deep Learning Models\n",
    "\n",
    "#How do you know if your model is underfitting? Your model is underfitting if the accuracy on the validation set \n",
    "#is higher than the accuracy on the training set. Additionally, \n",
    "#if the whole model performs bad this is also called underfitting.\n",
    "\n",
    "#https://towardsdatascience.com/deep-learning-3-more-on-cnns-handling-overfitting-2bd5d99abe5d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-4d5584460d175c59\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-4d5584460d175c59\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir logs/fit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3 test the CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Model\n",
    "classifier.load_weights('best_cnn.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 150, 150, 8)       224       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 75, 75, 8)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 75, 75, 16)        1168      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 37, 37, 16)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 21904)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 32)                700960    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 702,385\n",
      "Trainable params: 702,385\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "classifier.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 688 images belonging to 2 classes.\n",
      "Test Loss 0.3352488577365875\n",
      "Test accuracy 0.8735465407371521\n"
     ]
    }
   ],
   "source": [
    "test_set = datagen.flow_from_directory(parth_dir_test,\n",
    "                                        target_size= (150,150),\n",
    "                                        batch_size = 64,\n",
    "                                        seed = 11,\n",
    "                                        class_mode = 'binary',\n",
    "                                        shuffle=False)\n",
    "\n",
    "score = classifier.evaluate(test_set, verbose=0)\n",
    "\n",
    "print('Test Loss', score[0])\n",
    "print('Test accuracy', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\envs\\gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\sequential.py:455: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.88      0.87       344\n",
      "           1       0.88      0.87      0.87       344\n",
      "\n",
      "    accuracy                           0.87       688\n",
      "   macro avg       0.87      0.87      0.87       688\n",
      "weighted avg       0.87      0.87      0.87       688\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "yhat_classes = classifier.predict_classes(test_set, verbose=0)\n",
    "yhat_classes = yhat_classes[:, 0]\n",
    "\n",
    "print(classification_report(test_set.classes,yhat_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
