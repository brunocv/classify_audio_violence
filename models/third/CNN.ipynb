{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural Network\n",
    "\n",
    "### Part 1 - Building the CNN\n",
    "\n",
    "#### Importing the Tensorflow libraries and packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor Flow Version: 2.6.0\n",
      "Keras Version: 2.6.0\n",
      "\n",
      "Python 3.8.13 | packaged by conda-forge | (default, Mar 25 2022, 05:59:45) [MSC v.1929 64 bit (AMD64)]\n",
      "Pandas 1.4.3\n",
      "Scikit-Learn 1.1.1\n",
      "GPU is available\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "import tensorflow.keras\n",
    "import pandas as pd\n",
    "import sklearn as sk\n",
    "import tensorflow as tf\n",
    "\n",
    "print(f\"Tensor Flow Version: {tf.__version__}\")\n",
    "print(f\"Keras Version: {tensorflow.keras.__version__}\")\n",
    "print()\n",
    "print(f\"Python {sys.version}\")\n",
    "print(f\"Pandas {pd.__version__}\")\n",
    "print(f\"Scikit-Learn {sk.__version__}\")\n",
    "gpu = len(tf.config.list_physical_devices('GPU'))>0\n",
    "print(\"GPU is\", \"available\" if gpu else \"NOT AVAILABLE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the TensorBoard notebook extension\n",
    "%load_ext tensorboard\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, GlobalAveragePooling2D\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = Sequential()\n",
    "\n",
    "#classes = 2\n",
    "\n",
    "#Kernels usually 1x1 | 3x3 | 5x5\n",
    "\n",
    "#Adding a convolutional layer\n",
    "classifier.add(Conv2D(8, (3, 3), input_shape = (150, 150, 3), padding='same', activation = 'relu'))\n",
    "classifier.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "#Adding a second convolutional layer\n",
    "classifier.add(Conv2D(16, (3, 3), padding='same', activation = 'relu'))\n",
    "classifier.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "#Flattening\n",
    "classifier.add(Flatten())\n",
    "\n",
    "#Full connection\n",
    "classifier.add(Dense(units = 32, activation = 'relu'))\n",
    "classifier.add(Dropout(0.30))\n",
    "classifier.add(Dense(units = 1, activation= 'sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's double check the model description:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 150, 150, 8)       224       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 75, 75, 8)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 75, 75, 16)        1168      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 37, 37, 16)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 21904)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 32)                700960    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 702,385\n",
      "Trainable params: 702,385\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "classifier.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "opt = Adam(learning_rate=0.00001)\n",
    "classifier.compile(optimizer = opt, loss = 'binary_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2 - Fitting the CNN to the images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2202 images belonging to 2 classes.\n",
      "Found 550 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "path_dir = '../../dataset/train'\n",
    "parth_dir_test = '../../dataset/test'\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "                    rescale=1./255,\n",
    "                    validation_split = 0.2)\n",
    "\n",
    "train_generator = datagen.flow_from_directory(\n",
    "    path_dir,\n",
    "    target_size=(150,150),\n",
    "    shuffle=True,\n",
    "    subset='training',\n",
    "    batch_size = 64,\n",
    "    class_mode = 'binary'\n",
    ")\n",
    "validation_generator = datagen.flow_from_directory(\n",
    "    path_dir,\n",
    "    target_size=(150,150),\n",
    "    subset='validation',\n",
    "    batch_size = 64,\n",
    "    class_mode = 'binary'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'nonviolence': 0, 'violence': 1}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_generator.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, TensorBoard\n",
    "import datetime\n",
    "\n",
    "#rm -rf /logs/\n",
    "\n",
    "es = EarlyStopping(monitor='val_loss', patience=30)\n",
    "mc = ModelCheckpoint('best_cnn.h5', monitor='val_loss', mode='min', save_best_only=True)\n",
    "reduceLR = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=20)\n",
    "\n",
    "# Create a TensorBoard callback\n",
    "log_dir = \"logs\\\\fit\\\\\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "35/35 [==============================] - 14s 273ms/step - loss: 0.6864 - accuracy: 0.5372 - val_loss: 0.6773 - val_accuracy: 0.6236\n",
      "Epoch 2/200\n",
      "35/35 [==============================] - 7s 204ms/step - loss: 0.6771 - accuracy: 0.5904 - val_loss: 0.6680 - val_accuracy: 0.7073\n",
      "Epoch 3/200\n",
      "35/35 [==============================] - 7s 214ms/step - loss: 0.6700 - accuracy: 0.6167 - val_loss: 0.6573 - val_accuracy: 0.6964\n",
      "Epoch 4/200\n",
      "35/35 [==============================] - 8s 240ms/step - loss: 0.6618 - accuracy: 0.6535 - val_loss: 0.6458 - val_accuracy: 0.7600\n",
      "Epoch 5/200\n",
      "35/35 [==============================] - 7s 207ms/step - loss: 0.6502 - accuracy: 0.6735 - val_loss: 0.6406 - val_accuracy: 0.6436\n",
      "Epoch 6/200\n",
      "35/35 [==============================] - 7s 206ms/step - loss: 0.6406 - accuracy: 0.6857 - val_loss: 0.6257 - val_accuracy: 0.7436\n",
      "Epoch 7/200\n",
      "35/35 [==============================] - 7s 212ms/step - loss: 0.6332 - accuracy: 0.7016 - val_loss: 0.6129 - val_accuracy: 0.7873\n",
      "Epoch 8/200\n",
      "35/35 [==============================] - 7s 206ms/step - loss: 0.6268 - accuracy: 0.7107 - val_loss: 0.6049 - val_accuracy: 0.7709\n",
      "Epoch 9/200\n",
      "35/35 [==============================] - 7s 203ms/step - loss: 0.6167 - accuracy: 0.7171 - val_loss: 0.5948 - val_accuracy: 0.7818\n",
      "Epoch 10/200\n",
      "35/35 [==============================] - 7s 203ms/step - loss: 0.6096 - accuracy: 0.7171 - val_loss: 0.5864 - val_accuracy: 0.7818\n",
      "Epoch 11/200\n",
      "35/35 [==============================] - 7s 203ms/step - loss: 0.6039 - accuracy: 0.7252 - val_loss: 0.5771 - val_accuracy: 0.8055\n",
      "Epoch 12/200\n",
      "35/35 [==============================] - 7s 205ms/step - loss: 0.5932 - accuracy: 0.7298 - val_loss: 0.5680 - val_accuracy: 0.8018\n",
      "Epoch 13/200\n",
      "35/35 [==============================] - 7s 207ms/step - loss: 0.5913 - accuracy: 0.7348 - val_loss: 0.5603 - val_accuracy: 0.8073\n",
      "Epoch 14/200\n",
      "35/35 [==============================] - 7s 204ms/step - loss: 0.5813 - accuracy: 0.7520 - val_loss: 0.5549 - val_accuracy: 0.8055\n",
      "Epoch 15/200\n",
      "35/35 [==============================] - 7s 203ms/step - loss: 0.5757 - accuracy: 0.7384 - val_loss: 0.5525 - val_accuracy: 0.7618\n",
      "Epoch 16/200\n",
      "35/35 [==============================] - 7s 202ms/step - loss: 0.5701 - accuracy: 0.7520 - val_loss: 0.5505 - val_accuracy: 0.7455\n",
      "Epoch 17/200\n",
      "35/35 [==============================] - 7s 207ms/step - loss: 0.5696 - accuracy: 0.7348 - val_loss: 0.5334 - val_accuracy: 0.8164\n",
      "Epoch 18/200\n",
      "35/35 [==============================] - 7s 204ms/step - loss: 0.5622 - accuracy: 0.7470 - val_loss: 0.5258 - val_accuracy: 0.8291\n",
      "Epoch 19/200\n",
      "35/35 [==============================] - 7s 203ms/step - loss: 0.5546 - accuracy: 0.7507 - val_loss: 0.5204 - val_accuracy: 0.8309\n",
      "Epoch 20/200\n",
      "35/35 [==============================] - 7s 206ms/step - loss: 0.5489 - accuracy: 0.7620 - val_loss: 0.5145 - val_accuracy: 0.8309\n",
      "Epoch 21/200\n",
      "35/35 [==============================] - 7s 200ms/step - loss: 0.5454 - accuracy: 0.7602 - val_loss: 0.5074 - val_accuracy: 0.8400\n",
      "Epoch 22/200\n",
      "35/35 [==============================] - 7s 201ms/step - loss: 0.5426 - accuracy: 0.7570 - val_loss: 0.5073 - val_accuracy: 0.7982\n",
      "Epoch 23/200\n",
      "35/35 [==============================] - 7s 200ms/step - loss: 0.5334 - accuracy: 0.7589 - val_loss: 0.4976 - val_accuracy: 0.8364\n",
      "Epoch 24/200\n",
      "35/35 [==============================] - 7s 199ms/step - loss: 0.5275 - accuracy: 0.7748 - val_loss: 0.4920 - val_accuracy: 0.8436\n",
      "Epoch 25/200\n",
      "35/35 [==============================] - 7s 200ms/step - loss: 0.5221 - accuracy: 0.7734 - val_loss: 0.4895 - val_accuracy: 0.8255\n",
      "Epoch 26/200\n",
      "35/35 [==============================] - 7s 200ms/step - loss: 0.5237 - accuracy: 0.7725 - val_loss: 0.4827 - val_accuracy: 0.8509\n",
      "Epoch 27/200\n",
      "35/35 [==============================] - 7s 200ms/step - loss: 0.5162 - accuracy: 0.7729 - val_loss: 0.4825 - val_accuracy: 0.8218\n",
      "Epoch 28/200\n",
      "35/35 [==============================] - 7s 200ms/step - loss: 0.5142 - accuracy: 0.7743 - val_loss: 0.4746 - val_accuracy: 0.8509\n",
      "Epoch 29/200\n",
      "35/35 [==============================] - 7s 200ms/step - loss: 0.5124 - accuracy: 0.7743 - val_loss: 0.4715 - val_accuracy: 0.8491\n",
      "Epoch 30/200\n",
      "35/35 [==============================] - 7s 202ms/step - loss: 0.5095 - accuracy: 0.7761 - val_loss: 0.4683 - val_accuracy: 0.8509\n",
      "Epoch 31/200\n",
      "35/35 [==============================] - 7s 203ms/step - loss: 0.5058 - accuracy: 0.7761 - val_loss: 0.4651 - val_accuracy: 0.8582\n",
      "Epoch 32/200\n",
      "35/35 [==============================] - 7s 201ms/step - loss: 0.5011 - accuracy: 0.7929 - val_loss: 0.4615 - val_accuracy: 0.8545\n",
      "Epoch 33/200\n",
      "35/35 [==============================] - 7s 206ms/step - loss: 0.4984 - accuracy: 0.7875 - val_loss: 0.4581 - val_accuracy: 0.8618\n",
      "Epoch 34/200\n",
      "35/35 [==============================] - 7s 204ms/step - loss: 0.4971 - accuracy: 0.7861 - val_loss: 0.4572 - val_accuracy: 0.8436\n",
      "Epoch 35/200\n",
      "35/35 [==============================] - 7s 205ms/step - loss: 0.4931 - accuracy: 0.7902 - val_loss: 0.4537 - val_accuracy: 0.8600\n",
      "Epoch 36/200\n",
      "35/35 [==============================] - 7s 203ms/step - loss: 0.4933 - accuracy: 0.7888 - val_loss: 0.4590 - val_accuracy: 0.8182\n",
      "Epoch 37/200\n",
      "35/35 [==============================] - 7s 202ms/step - loss: 0.4854 - accuracy: 0.7929 - val_loss: 0.4489 - val_accuracy: 0.8509\n",
      "Epoch 38/200\n",
      "35/35 [==============================] - 7s 203ms/step - loss: 0.4902 - accuracy: 0.7947 - val_loss: 0.4464 - val_accuracy: 0.8564\n",
      "Epoch 39/200\n",
      "35/35 [==============================] - 7s 201ms/step - loss: 0.4774 - accuracy: 0.7979 - val_loss: 0.4467 - val_accuracy: 0.8309\n",
      "Epoch 40/200\n",
      "35/35 [==============================] - 7s 202ms/step - loss: 0.4808 - accuracy: 0.7934 - val_loss: 0.4413 - val_accuracy: 0.8582\n",
      "Epoch 41/200\n",
      "35/35 [==============================] - 7s 202ms/step - loss: 0.4804 - accuracy: 0.7965 - val_loss: 0.4391 - val_accuracy: 0.8600\n",
      "Epoch 42/200\n",
      "35/35 [==============================] - 7s 201ms/step - loss: 0.4727 - accuracy: 0.8038 - val_loss: 0.4396 - val_accuracy: 0.8473\n",
      "Epoch 43/200\n",
      "35/35 [==============================] - 7s 199ms/step - loss: 0.4703 - accuracy: 0.7993 - val_loss: 0.4343 - val_accuracy: 0.8582\n",
      "Epoch 44/200\n",
      "35/35 [==============================] - 7s 204ms/step - loss: 0.4663 - accuracy: 0.8097 - val_loss: 0.4331 - val_accuracy: 0.8582\n",
      "Epoch 45/200\n",
      "35/35 [==============================] - 7s 204ms/step - loss: 0.4674 - accuracy: 0.8020 - val_loss: 0.4330 - val_accuracy: 0.8527\n",
      "Epoch 46/200\n",
      "35/35 [==============================] - 7s 204ms/step - loss: 0.4715 - accuracy: 0.8029 - val_loss: 0.4313 - val_accuracy: 0.8545\n",
      "Epoch 47/200\n",
      "35/35 [==============================] - 7s 207ms/step - loss: 0.4662 - accuracy: 0.8052 - val_loss: 0.4287 - val_accuracy: 0.8564\n",
      "Epoch 48/200\n",
      "35/35 [==============================] - 7s 202ms/step - loss: 0.4659 - accuracy: 0.8074 - val_loss: 0.4267 - val_accuracy: 0.8545\n",
      "Epoch 49/200\n",
      "35/35 [==============================] - 7s 211ms/step - loss: 0.4634 - accuracy: 0.8056 - val_loss: 0.4271 - val_accuracy: 0.8564\n",
      "Epoch 50/200\n",
      "35/35 [==============================] - 8s 220ms/step - loss: 0.4644 - accuracy: 0.8029 - val_loss: 0.4248 - val_accuracy: 0.8545\n",
      "Epoch 51/200\n",
      "35/35 [==============================] - 7s 214ms/step - loss: 0.4577 - accuracy: 0.8174 - val_loss: 0.4267 - val_accuracy: 0.8455\n",
      "Epoch 52/200\n",
      "35/35 [==============================] - 8s 219ms/step - loss: 0.4560 - accuracy: 0.8152 - val_loss: 0.4225 - val_accuracy: 0.8564\n",
      "Epoch 53/200\n",
      "35/35 [==============================] - 7s 208ms/step - loss: 0.4512 - accuracy: 0.8170 - val_loss: 0.4220 - val_accuracy: 0.8545\n",
      "Epoch 54/200\n",
      "35/35 [==============================] - 8s 223ms/step - loss: 0.4517 - accuracy: 0.8120 - val_loss: 0.4245 - val_accuracy: 0.8455\n",
      "Epoch 55/200\n",
      "35/35 [==============================] - 7s 207ms/step - loss: 0.4556 - accuracy: 0.8097 - val_loss: 0.4200 - val_accuracy: 0.8618\n",
      "Epoch 56/200\n",
      "35/35 [==============================] - 7s 201ms/step - loss: 0.4503 - accuracy: 0.8161 - val_loss: 0.4169 - val_accuracy: 0.8600\n",
      "Epoch 57/200\n",
      "35/35 [==============================] - 7s 205ms/step - loss: 0.4436 - accuracy: 0.8215 - val_loss: 0.4162 - val_accuracy: 0.8582\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/200\n",
      "35/35 [==============================] - 7s 213ms/step - loss: 0.4386 - accuracy: 0.8215 - val_loss: 0.4155 - val_accuracy: 0.8545\n",
      "Epoch 59/200\n",
      "35/35 [==============================] - 7s 208ms/step - loss: 0.4419 - accuracy: 0.8174 - val_loss: 0.4126 - val_accuracy: 0.8600\n",
      "Epoch 60/200\n",
      "35/35 [==============================] - 8s 231ms/step - loss: 0.4456 - accuracy: 0.8129 - val_loss: 0.4185 - val_accuracy: 0.8509\n",
      "Epoch 61/200\n",
      "35/35 [==============================] - 8s 226ms/step - loss: 0.4406 - accuracy: 0.8179 - val_loss: 0.4114 - val_accuracy: 0.8600\n",
      "Epoch 62/200\n",
      "35/35 [==============================] - 8s 216ms/step - loss: 0.4424 - accuracy: 0.8311 - val_loss: 0.4106 - val_accuracy: 0.8600\n",
      "Epoch 63/200\n",
      "35/35 [==============================] - 8s 215ms/step - loss: 0.4386 - accuracy: 0.8179 - val_loss: 0.4107 - val_accuracy: 0.8600\n",
      "Epoch 64/200\n",
      "35/35 [==============================] - 8s 218ms/step - loss: 0.4396 - accuracy: 0.8256 - val_loss: 0.4106 - val_accuracy: 0.8545\n",
      "Epoch 65/200\n",
      "35/35 [==============================] - 8s 217ms/step - loss: 0.4310 - accuracy: 0.8229 - val_loss: 0.4089 - val_accuracy: 0.8600\n",
      "Epoch 66/200\n",
      "35/35 [==============================] - 7s 215ms/step - loss: 0.4349 - accuracy: 0.8252 - val_loss: 0.4111 - val_accuracy: 0.8564\n",
      "Epoch 67/200\n",
      "35/35 [==============================] - 8s 216ms/step - loss: 0.4296 - accuracy: 0.8256 - val_loss: 0.4063 - val_accuracy: 0.8582\n",
      "Epoch 68/200\n",
      "35/35 [==============================] - 7s 215ms/step - loss: 0.4299 - accuracy: 0.8302 - val_loss: 0.4050 - val_accuracy: 0.8582\n",
      "Epoch 69/200\n",
      "35/35 [==============================] - 7s 203ms/step - loss: 0.4300 - accuracy: 0.8306 - val_loss: 0.4047 - val_accuracy: 0.8600\n",
      "Epoch 70/200\n",
      "35/35 [==============================] - 8s 215ms/step - loss: 0.4310 - accuracy: 0.8206 - val_loss: 0.4065 - val_accuracy: 0.8509\n",
      "Epoch 71/200\n",
      "35/35 [==============================] - 7s 211ms/step - loss: 0.4275 - accuracy: 0.8265 - val_loss: 0.4028 - val_accuracy: 0.8600\n",
      "Epoch 72/200\n",
      "35/35 [==============================] - 8s 217ms/step - loss: 0.4221 - accuracy: 0.8374 - val_loss: 0.4047 - val_accuracy: 0.8509\n",
      "Epoch 73/200\n",
      "35/35 [==============================] - 7s 213ms/step - loss: 0.4307 - accuracy: 0.8265 - val_loss: 0.4021 - val_accuracy: 0.8618\n",
      "Epoch 74/200\n",
      "35/35 [==============================] - 7s 211ms/step - loss: 0.4249 - accuracy: 0.8333 - val_loss: 0.4015 - val_accuracy: 0.8636\n",
      "Epoch 75/200\n",
      "35/35 [==============================] - 7s 213ms/step - loss: 0.4220 - accuracy: 0.8315 - val_loss: 0.4077 - val_accuracy: 0.8564\n",
      "Epoch 76/200\n",
      "35/35 [==============================] - 8s 217ms/step - loss: 0.4185 - accuracy: 0.8342 - val_loss: 0.4003 - val_accuracy: 0.8600\n",
      "Epoch 77/200\n",
      "35/35 [==============================] - 8s 215ms/step - loss: 0.4263 - accuracy: 0.8324 - val_loss: 0.3973 - val_accuracy: 0.8582\n",
      "Epoch 78/200\n",
      "35/35 [==============================] - 8s 219ms/step - loss: 0.4253 - accuracy: 0.8306 - val_loss: 0.4008 - val_accuracy: 0.8509\n",
      "Epoch 79/200\n",
      "35/35 [==============================] - 8s 222ms/step - loss: 0.4168 - accuracy: 0.8379 - val_loss: 0.3980 - val_accuracy: 0.8618\n",
      "Epoch 80/200\n",
      "35/35 [==============================] - 7s 212ms/step - loss: 0.4153 - accuracy: 0.8370 - val_loss: 0.3971 - val_accuracy: 0.8564\n",
      "Epoch 81/200\n",
      "35/35 [==============================] - 7s 208ms/step - loss: 0.4202 - accuracy: 0.8333 - val_loss: 0.3943 - val_accuracy: 0.8636\n",
      "Epoch 82/200\n",
      "35/35 [==============================] - 7s 209ms/step - loss: 0.4094 - accuracy: 0.8383 - val_loss: 0.3924 - val_accuracy: 0.8636\n",
      "Epoch 83/200\n",
      "35/35 [==============================] - 7s 207ms/step - loss: 0.4108 - accuracy: 0.8342 - val_loss: 0.3923 - val_accuracy: 0.8636\n",
      "Epoch 84/200\n",
      "35/35 [==============================] - 7s 209ms/step - loss: 0.4128 - accuracy: 0.8388 - val_loss: 0.3930 - val_accuracy: 0.8582\n",
      "Epoch 85/200\n",
      "35/35 [==============================] - 7s 214ms/step - loss: 0.4107 - accuracy: 0.8365 - val_loss: 0.3910 - val_accuracy: 0.8673\n",
      "Epoch 86/200\n",
      "35/35 [==============================] - 7s 208ms/step - loss: 0.4052 - accuracy: 0.8447 - val_loss: 0.3900 - val_accuracy: 0.8691\n",
      "Epoch 87/200\n",
      "35/35 [==============================] - 7s 208ms/step - loss: 0.4087 - accuracy: 0.8383 - val_loss: 0.3911 - val_accuracy: 0.8600\n",
      "Epoch 88/200\n",
      "35/35 [==============================] - 7s 207ms/step - loss: 0.4116 - accuracy: 0.8429 - val_loss: 0.3913 - val_accuracy: 0.8600\n",
      "Epoch 89/200\n",
      "35/35 [==============================] - 7s 206ms/step - loss: 0.4119 - accuracy: 0.8411 - val_loss: 0.3935 - val_accuracy: 0.8491\n",
      "Epoch 90/200\n",
      "35/35 [==============================] - 7s 207ms/step - loss: 0.4102 - accuracy: 0.8333 - val_loss: 0.3882 - val_accuracy: 0.8691\n",
      "Epoch 91/200\n",
      "35/35 [==============================] - 7s 206ms/step - loss: 0.4054 - accuracy: 0.8488 - val_loss: 0.3873 - val_accuracy: 0.8673\n",
      "Epoch 92/200\n",
      "35/35 [==============================] - 7s 207ms/step - loss: 0.4011 - accuracy: 0.8397 - val_loss: 0.3903 - val_accuracy: 0.8509\n",
      "Epoch 93/200\n",
      "35/35 [==============================] - 7s 211ms/step - loss: 0.4041 - accuracy: 0.8424 - val_loss: 0.3857 - val_accuracy: 0.8727\n",
      "Epoch 94/200\n",
      "35/35 [==============================] - 7s 208ms/step - loss: 0.3973 - accuracy: 0.8497 - val_loss: 0.3844 - val_accuracy: 0.8691\n",
      "Epoch 95/200\n",
      "35/35 [==============================] - 7s 206ms/step - loss: 0.4001 - accuracy: 0.8470 - val_loss: 0.3844 - val_accuracy: 0.8636\n",
      "Epoch 96/200\n",
      "35/35 [==============================] - 7s 209ms/step - loss: 0.3982 - accuracy: 0.8438 - val_loss: 0.3833 - val_accuracy: 0.8691\n",
      "Epoch 97/200\n",
      "35/35 [==============================] - 7s 208ms/step - loss: 0.4050 - accuracy: 0.8365 - val_loss: 0.3836 - val_accuracy: 0.8655\n",
      "Epoch 98/200\n",
      "35/35 [==============================] - 7s 206ms/step - loss: 0.3968 - accuracy: 0.8470 - val_loss: 0.3829 - val_accuracy: 0.8655\n",
      "Epoch 99/200\n",
      "35/35 [==============================] - 8s 215ms/step - loss: 0.3970 - accuracy: 0.8447 - val_loss: 0.3809 - val_accuracy: 0.8673\n",
      "Epoch 100/200\n",
      "35/35 [==============================] - 8s 217ms/step - loss: 0.3966 - accuracy: 0.8451 - val_loss: 0.3808 - val_accuracy: 0.8691\n",
      "Epoch 101/200\n",
      "35/35 [==============================] - 7s 210ms/step - loss: 0.3942 - accuracy: 0.8574 - val_loss: 0.3792 - val_accuracy: 0.8691\n",
      "Epoch 102/200\n",
      "35/35 [==============================] - 8s 217ms/step - loss: 0.3904 - accuracy: 0.8479 - val_loss: 0.3797 - val_accuracy: 0.8691\n",
      "Epoch 103/200\n",
      "35/35 [==============================] - 7s 214ms/step - loss: 0.3937 - accuracy: 0.8492 - val_loss: 0.3775 - val_accuracy: 0.8691\n",
      "Epoch 104/200\n",
      "35/35 [==============================] - 8s 219ms/step - loss: 0.3956 - accuracy: 0.8424 - val_loss: 0.3834 - val_accuracy: 0.8545\n",
      "Epoch 105/200\n",
      "35/35 [==============================] - 7s 215ms/step - loss: 0.3931 - accuracy: 0.8451 - val_loss: 0.3770 - val_accuracy: 0.8727\n",
      "Epoch 106/200\n",
      "35/35 [==============================] - 7s 215ms/step - loss: 0.3882 - accuracy: 0.8451 - val_loss: 0.3786 - val_accuracy: 0.8618\n",
      "Epoch 107/200\n",
      "35/35 [==============================] - 7s 209ms/step - loss: 0.3897 - accuracy: 0.8479 - val_loss: 0.3750 - val_accuracy: 0.8691\n",
      "Epoch 108/200\n",
      "35/35 [==============================] - 7s 210ms/step - loss: 0.3837 - accuracy: 0.8515 - val_loss: 0.3770 - val_accuracy: 0.8673\n",
      "Epoch 109/200\n",
      "35/35 [==============================] - 8s 215ms/step - loss: 0.3929 - accuracy: 0.8456 - val_loss: 0.3776 - val_accuracy: 0.8618\n",
      "Epoch 110/200\n",
      "35/35 [==============================] - 7s 210ms/step - loss: 0.3883 - accuracy: 0.8479 - val_loss: 0.3757 - val_accuracy: 0.8600\n",
      "Epoch 111/200\n",
      "35/35 [==============================] - 8s 221ms/step - loss: 0.3841 - accuracy: 0.8510 - val_loss: 0.3719 - val_accuracy: 0.8782\n",
      "Epoch 112/200\n",
      "35/35 [==============================] - 7s 209ms/step - loss: 0.3835 - accuracy: 0.8438 - val_loss: 0.3746 - val_accuracy: 0.8600\n",
      "Epoch 113/200\n",
      "35/35 [==============================] - 7s 206ms/step - loss: 0.3848 - accuracy: 0.8515 - val_loss: 0.3712 - val_accuracy: 0.8727\n",
      "Epoch 114/200\n",
      "35/35 [==============================] - 7s 208ms/step - loss: 0.3789 - accuracy: 0.8574 - val_loss: 0.3705 - val_accuracy: 0.8709\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 115/200\n",
      "35/35 [==============================] - 7s 211ms/step - loss: 0.3831 - accuracy: 0.8565 - val_loss: 0.3706 - val_accuracy: 0.8691\n",
      "Epoch 116/200\n",
      "35/35 [==============================] - 7s 209ms/step - loss: 0.3818 - accuracy: 0.8506 - val_loss: 0.3713 - val_accuracy: 0.8745\n",
      "Epoch 117/200\n",
      "35/35 [==============================] - 7s 211ms/step - loss: 0.3888 - accuracy: 0.8479 - val_loss: 0.3715 - val_accuracy: 0.8655\n",
      "Epoch 118/200\n",
      "35/35 [==============================] - 7s 213ms/step - loss: 0.3741 - accuracy: 0.8565 - val_loss: 0.3688 - val_accuracy: 0.8709\n",
      "Epoch 119/200\n",
      "35/35 [==============================] - 7s 206ms/step - loss: 0.3758 - accuracy: 0.8547 - val_loss: 0.3684 - val_accuracy: 0.8709\n",
      "Epoch 120/200\n",
      "35/35 [==============================] - 8s 216ms/step - loss: 0.3765 - accuracy: 0.8520 - val_loss: 0.3674 - val_accuracy: 0.8782\n",
      "Epoch 121/200\n",
      "35/35 [==============================] - 7s 207ms/step - loss: 0.3784 - accuracy: 0.8597 - val_loss: 0.3681 - val_accuracy: 0.8618\n",
      "Epoch 122/200\n",
      "35/35 [==============================] - 7s 208ms/step - loss: 0.3759 - accuracy: 0.8547 - val_loss: 0.3651 - val_accuracy: 0.8818\n",
      "Epoch 123/200\n",
      "35/35 [==============================] - 7s 211ms/step - loss: 0.3765 - accuracy: 0.8542 - val_loss: 0.3641 - val_accuracy: 0.8800\n",
      "Epoch 124/200\n",
      "35/35 [==============================] - 7s 209ms/step - loss: 0.3762 - accuracy: 0.8538 - val_loss: 0.3634 - val_accuracy: 0.8818\n",
      "Epoch 125/200\n",
      "35/35 [==============================] - 7s 213ms/step - loss: 0.3700 - accuracy: 0.8597 - val_loss: 0.3633 - val_accuracy: 0.8800\n",
      "Epoch 126/200\n",
      "35/35 [==============================] - 7s 208ms/step - loss: 0.3736 - accuracy: 0.8569 - val_loss: 0.3640 - val_accuracy: 0.8764\n",
      "Epoch 127/200\n",
      "35/35 [==============================] - 7s 211ms/step - loss: 0.3692 - accuracy: 0.8597 - val_loss: 0.3606 - val_accuracy: 0.8818\n",
      "Epoch 128/200\n",
      "35/35 [==============================] - 7s 210ms/step - loss: 0.3708 - accuracy: 0.8551 - val_loss: 0.3611 - val_accuracy: 0.8800\n",
      "Epoch 129/200\n",
      "35/35 [==============================] - 8s 217ms/step - loss: 0.3631 - accuracy: 0.8606 - val_loss: 0.3596 - val_accuracy: 0.8782\n",
      "Epoch 130/200\n",
      "35/35 [==============================] - 7s 206ms/step - loss: 0.3721 - accuracy: 0.8529 - val_loss: 0.3600 - val_accuracy: 0.8764\n",
      "Epoch 131/200\n",
      "35/35 [==============================] - 7s 204ms/step - loss: 0.3667 - accuracy: 0.8592 - val_loss: 0.3604 - val_accuracy: 0.8709\n",
      "Epoch 132/200\n",
      "35/35 [==============================] - 7s 203ms/step - loss: 0.3623 - accuracy: 0.8569 - val_loss: 0.3577 - val_accuracy: 0.8782\n",
      "Epoch 133/200\n",
      "35/35 [==============================] - 7s 211ms/step - loss: 0.3694 - accuracy: 0.8583 - val_loss: 0.3599 - val_accuracy: 0.8709\n",
      "Epoch 134/200\n",
      "35/35 [==============================] - 7s 210ms/step - loss: 0.3717 - accuracy: 0.8574 - val_loss: 0.3587 - val_accuracy: 0.8673\n",
      "Epoch 135/200\n",
      "35/35 [==============================] - 7s 208ms/step - loss: 0.3611 - accuracy: 0.8610 - val_loss: 0.3560 - val_accuracy: 0.8818\n",
      "Epoch 136/200\n",
      "35/35 [==============================] - 7s 206ms/step - loss: 0.3637 - accuracy: 0.8619 - val_loss: 0.3571 - val_accuracy: 0.8800\n",
      "Epoch 137/200\n",
      "35/35 [==============================] - 7s 210ms/step - loss: 0.3636 - accuracy: 0.8642 - val_loss: 0.3551 - val_accuracy: 0.8873\n",
      "Epoch 138/200\n",
      "35/35 [==============================] - 7s 207ms/step - loss: 0.3595 - accuracy: 0.8601 - val_loss: 0.3603 - val_accuracy: 0.8600\n",
      "Epoch 139/200\n",
      "35/35 [==============================] - 8s 218ms/step - loss: 0.3654 - accuracy: 0.8629 - val_loss: 0.3556 - val_accuracy: 0.8818\n",
      "Epoch 140/200\n",
      "35/35 [==============================] - 8s 220ms/step - loss: 0.3633 - accuracy: 0.8638 - val_loss: 0.3537 - val_accuracy: 0.8782\n",
      "Epoch 141/200\n",
      "35/35 [==============================] - 7s 208ms/step - loss: 0.3601 - accuracy: 0.8674 - val_loss: 0.3580 - val_accuracy: 0.8636\n",
      "Epoch 142/200\n",
      "35/35 [==============================] - 7s 211ms/step - loss: 0.3608 - accuracy: 0.8624 - val_loss: 0.3537 - val_accuracy: 0.8727\n",
      "Epoch 143/200\n",
      "35/35 [==============================] - 8s 219ms/step - loss: 0.3561 - accuracy: 0.8697 - val_loss: 0.3507 - val_accuracy: 0.8782\n",
      "Epoch 144/200\n",
      "35/35 [==============================] - 8s 215ms/step - loss: 0.3596 - accuracy: 0.8656 - val_loss: 0.3557 - val_accuracy: 0.8655\n",
      "Epoch 145/200\n",
      "35/35 [==============================] - 8s 217ms/step - loss: 0.3580 - accuracy: 0.8633 - val_loss: 0.3495 - val_accuracy: 0.8818\n",
      "Epoch 146/200\n",
      "35/35 [==============================] - 7s 211ms/step - loss: 0.3525 - accuracy: 0.8683 - val_loss: 0.3520 - val_accuracy: 0.8691\n",
      "Epoch 147/200\n",
      "35/35 [==============================] - 8s 218ms/step - loss: 0.3620 - accuracy: 0.8638 - val_loss: 0.3488 - val_accuracy: 0.8818\n",
      "Epoch 148/200\n",
      "35/35 [==============================] - 8s 216ms/step - loss: 0.3550 - accuracy: 0.8638 - val_loss: 0.3478 - val_accuracy: 0.8836\n",
      "Epoch 149/200\n",
      "35/35 [==============================] - 8s 218ms/step - loss: 0.3537 - accuracy: 0.8647 - val_loss: 0.3513 - val_accuracy: 0.8673\n",
      "Epoch 150/200\n",
      "35/35 [==============================] - 8s 222ms/step - loss: 0.3564 - accuracy: 0.8715 - val_loss: 0.3480 - val_accuracy: 0.8782\n",
      "Epoch 151/200\n",
      "35/35 [==============================] - 7s 212ms/step - loss: 0.3513 - accuracy: 0.8701 - val_loss: 0.3475 - val_accuracy: 0.8836\n",
      "Epoch 152/200\n",
      "35/35 [==============================] - 7s 210ms/step - loss: 0.3547 - accuracy: 0.8642 - val_loss: 0.3476 - val_accuracy: 0.8782\n",
      "Epoch 153/200\n",
      "35/35 [==============================] - 7s 208ms/step - loss: 0.3514 - accuracy: 0.8683 - val_loss: 0.3455 - val_accuracy: 0.8764\n",
      "Epoch 154/200\n",
      "35/35 [==============================] - 7s 210ms/step - loss: 0.3445 - accuracy: 0.8801 - val_loss: 0.3485 - val_accuracy: 0.8655\n",
      "Epoch 155/200\n",
      "35/35 [==============================] - 7s 207ms/step - loss: 0.3464 - accuracy: 0.8688 - val_loss: 0.3437 - val_accuracy: 0.8764\n",
      "Epoch 156/200\n",
      "35/35 [==============================] - 7s 206ms/step - loss: 0.3460 - accuracy: 0.8701 - val_loss: 0.3438 - val_accuracy: 0.8709\n",
      "Epoch 157/200\n",
      "35/35 [==============================] - 7s 208ms/step - loss: 0.3423 - accuracy: 0.8724 - val_loss: 0.3417 - val_accuracy: 0.8782\n",
      "Epoch 158/200\n",
      "35/35 [==============================] - 7s 209ms/step - loss: 0.3451 - accuracy: 0.8724 - val_loss: 0.3427 - val_accuracy: 0.8836\n",
      "Epoch 159/200\n",
      "35/35 [==============================] - 7s 205ms/step - loss: 0.3461 - accuracy: 0.8715 - val_loss: 0.3427 - val_accuracy: 0.8855\n",
      "Epoch 160/200\n",
      "35/35 [==============================] - 7s 205ms/step - loss: 0.3488 - accuracy: 0.8669 - val_loss: 0.3401 - val_accuracy: 0.8818\n",
      "Epoch 161/200\n",
      "35/35 [==============================] - 7s 204ms/step - loss: 0.3453 - accuracy: 0.8742 - val_loss: 0.3419 - val_accuracy: 0.8727\n",
      "Epoch 162/200\n",
      "35/35 [==============================] - 7s 208ms/step - loss: 0.3386 - accuracy: 0.8674 - val_loss: 0.3413 - val_accuracy: 0.8691\n",
      "Epoch 163/200\n",
      "35/35 [==============================] - 7s 207ms/step - loss: 0.3440 - accuracy: 0.8706 - val_loss: 0.3392 - val_accuracy: 0.8818\n",
      "Epoch 164/200\n",
      "35/35 [==============================] - 7s 213ms/step - loss: 0.3432 - accuracy: 0.8697 - val_loss: 0.3411 - val_accuracy: 0.8691\n",
      "Epoch 165/200\n",
      "35/35 [==============================] - 7s 217ms/step - loss: 0.3449 - accuracy: 0.8683 - val_loss: 0.3406 - val_accuracy: 0.8709\n",
      "Epoch 166/200\n",
      "35/35 [==============================] - 7s 209ms/step - loss: 0.3443 - accuracy: 0.8765 - val_loss: 0.3399 - val_accuracy: 0.8782\n",
      "Epoch 167/200\n",
      "35/35 [==============================] - 7s 204ms/step - loss: 0.3376 - accuracy: 0.8715 - val_loss: 0.3484 - val_accuracy: 0.8527\n",
      "Epoch 168/200\n",
      "35/35 [==============================] - 7s 204ms/step - loss: 0.3367 - accuracy: 0.8719 - val_loss: 0.3375 - val_accuracy: 0.8782\n",
      "Epoch 169/200\n",
      "35/35 [==============================] - 7s 205ms/step - loss: 0.3409 - accuracy: 0.8774 - val_loss: 0.3383 - val_accuracy: 0.8818\n",
      "Epoch 170/200\n",
      "35/35 [==============================] - 7s 208ms/step - loss: 0.3397 - accuracy: 0.8756 - val_loss: 0.3349 - val_accuracy: 0.8855\n",
      "Epoch 171/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - 7s 212ms/step - loss: 0.3373 - accuracy: 0.8728 - val_loss: 0.3337 - val_accuracy: 0.8855\n",
      "Epoch 172/200\n",
      "35/35 [==============================] - 7s 212ms/step - loss: 0.3313 - accuracy: 0.8742 - val_loss: 0.3387 - val_accuracy: 0.8673\n",
      "Epoch 173/200\n",
      "35/35 [==============================] - 7s 211ms/step - loss: 0.3320 - accuracy: 0.8751 - val_loss: 0.3384 - val_accuracy: 0.8655\n",
      "Epoch 174/200\n",
      "35/35 [==============================] - 7s 213ms/step - loss: 0.3361 - accuracy: 0.8728 - val_loss: 0.3334 - val_accuracy: 0.8782\n",
      "Epoch 175/200\n",
      "35/35 [==============================] - 8s 217ms/step - loss: 0.3352 - accuracy: 0.8819 - val_loss: 0.3348 - val_accuracy: 0.8727\n",
      "Epoch 176/200\n",
      "35/35 [==============================] - 8s 216ms/step - loss: 0.3282 - accuracy: 0.8774 - val_loss: 0.3303 - val_accuracy: 0.8873\n",
      "Epoch 177/200\n",
      "35/35 [==============================] - 8s 221ms/step - loss: 0.3305 - accuracy: 0.8797 - val_loss: 0.3305 - val_accuracy: 0.8873\n",
      "Epoch 178/200\n",
      "35/35 [==============================] - 7s 206ms/step - loss: 0.3355 - accuracy: 0.8774 - val_loss: 0.3315 - val_accuracy: 0.8855\n",
      "Epoch 179/200\n",
      "35/35 [==============================] - 8s 224ms/step - loss: 0.3255 - accuracy: 0.8783 - val_loss: 0.3293 - val_accuracy: 0.8800\n",
      "Epoch 180/200\n",
      "35/35 [==============================] - 7s 214ms/step - loss: 0.3329 - accuracy: 0.8738 - val_loss: 0.3293 - val_accuracy: 0.8891\n",
      "Epoch 181/200\n",
      "35/35 [==============================] - 7s 208ms/step - loss: 0.3293 - accuracy: 0.8824 - val_loss: 0.3337 - val_accuracy: 0.8691\n",
      "Epoch 182/200\n",
      "35/35 [==============================] - 8s 226ms/step - loss: 0.3296 - accuracy: 0.8797 - val_loss: 0.3353 - val_accuracy: 0.8655\n",
      "Epoch 183/200\n",
      "35/35 [==============================] - 8s 215ms/step - loss: 0.3246 - accuracy: 0.8878 - val_loss: 0.3278 - val_accuracy: 0.8836\n",
      "Epoch 184/200\n",
      "35/35 [==============================] - 8s 215ms/step - loss: 0.3261 - accuracy: 0.8819 - val_loss: 0.3263 - val_accuracy: 0.8891\n",
      "Epoch 185/200\n",
      "35/35 [==============================] - 8s 227ms/step - loss: 0.3266 - accuracy: 0.8847 - val_loss: 0.3271 - val_accuracy: 0.8891\n",
      "Epoch 186/200\n",
      "35/35 [==============================] - 8s 223ms/step - loss: 0.3273 - accuracy: 0.8783 - val_loss: 0.3300 - val_accuracy: 0.8745\n",
      "Epoch 187/200\n",
      "35/35 [==============================] - 8s 217ms/step - loss: 0.3241 - accuracy: 0.8833 - val_loss: 0.3296 - val_accuracy: 0.8727\n",
      "Epoch 188/200\n",
      "35/35 [==============================] - 7s 211ms/step - loss: 0.3255 - accuracy: 0.8869 - val_loss: 0.3254 - val_accuracy: 0.8836\n",
      "Epoch 189/200\n",
      "35/35 [==============================] - 7s 212ms/step - loss: 0.3241 - accuracy: 0.8810 - val_loss: 0.3278 - val_accuracy: 0.8745\n",
      "Epoch 190/200\n",
      "35/35 [==============================] - 8s 232ms/step - loss: 0.3215 - accuracy: 0.8865 - val_loss: 0.3232 - val_accuracy: 0.8909\n",
      "Epoch 191/200\n",
      "35/35 [==============================] - 7s 214ms/step - loss: 0.3261 - accuracy: 0.8797 - val_loss: 0.3343 - val_accuracy: 0.8655\n",
      "Epoch 192/200\n",
      "35/35 [==============================] - 7s 212ms/step - loss: 0.3260 - accuracy: 0.8837 - val_loss: 0.3246 - val_accuracy: 0.8836\n",
      "Epoch 193/200\n",
      "35/35 [==============================] - 8s 218ms/step - loss: 0.3211 - accuracy: 0.8787 - val_loss: 0.3247 - val_accuracy: 0.8782\n",
      "Epoch 194/200\n",
      "35/35 [==============================] - 7s 209ms/step - loss: 0.3221 - accuracy: 0.8837 - val_loss: 0.3219 - val_accuracy: 0.8909\n",
      "Epoch 195/200\n",
      "35/35 [==============================] - 8s 219ms/step - loss: 0.3199 - accuracy: 0.8869 - val_loss: 0.3221 - val_accuracy: 0.8818\n",
      "Epoch 196/200\n",
      "35/35 [==============================] - 8s 225ms/step - loss: 0.3102 - accuracy: 0.8901 - val_loss: 0.3201 - val_accuracy: 0.8818\n",
      "Epoch 197/200\n",
      "35/35 [==============================] - 8s 220ms/step - loss: 0.3163 - accuracy: 0.8860 - val_loss: 0.3216 - val_accuracy: 0.8836\n",
      "Epoch 198/200\n",
      "35/35 [==============================] - 7s 214ms/step - loss: 0.3208 - accuracy: 0.8824 - val_loss: 0.3201 - val_accuracy: 0.8836\n",
      "Epoch 199/200\n",
      "35/35 [==============================] - 8s 231ms/step - loss: 0.3155 - accuracy: 0.8847 - val_loss: 0.3268 - val_accuracy: 0.8673\n",
      "Epoch 200/200\n",
      "35/35 [==============================] - 8s 216ms/step - loss: 0.3168 - accuracy: 0.8815 - val_loss: 0.3208 - val_accuracy: 0.8836\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1c942ecc9a0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit(train_generator,\n",
    "                         epochs = 200,\n",
    "                         callbacks = [tensorboard_callback,es,mc,reduceLR],\n",
    "                         validation_data = validation_generator\n",
    "                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Overfitting -> Your training accuracy will be higher than the accuracy on the validation/test set\n",
    "\n",
    "#Overfitting indicates that your model is too complex for the problem that it is solving,\n",
    "#filters in the case of Convolutional Neural Networks, and layers in the case of overall Deep Learning Models\n",
    "\n",
    "#How do you know if your model is underfitting? Your model is underfitting if the accuracy on the validation set \n",
    "#is higher than the accuracy on the training set. Additionally, \n",
    "#if the whole model performs bad this is also called underfitting.\n",
    "\n",
    "#https://towardsdatascience.com/deep-learning-3-more-on-cnns-handling-overfitting-2bd5d99abe5d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-6e4cd08678868c98\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-6e4cd08678868c98\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir logs/fit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3 test the CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Model\n",
    "classifier.load_weights('best_cnn.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 150, 150, 8)       224       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 75, 75, 8)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 75, 75, 16)        1168      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 37, 37, 16)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 21904)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 32)                700960    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 702,385\n",
      "Trainable params: 702,385\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "classifier.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 688 images belonging to 2 classes.\n",
      "Test Loss 0.35772812366485596\n",
      "Test accuracy 0.875\n"
     ]
    }
   ],
   "source": [
    "test_set = datagen.flow_from_directory(parth_dir_test,\n",
    "                                        target_size= (150,150),\n",
    "                                        batch_size = 64,\n",
    "                                        class_mode = 'binary',\n",
    "                                        shuffle=False)\n",
    "\n",
    "score = classifier.evaluate(test_set, verbose=0)\n",
    "\n",
    "print('Test Loss', score[0])\n",
    "print('Test accuracy', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\envs\\gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\sequential.py:455: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.85      0.87       344\n",
      "           1       0.86      0.90      0.88       344\n",
      "\n",
      "    accuracy                           0.88       688\n",
      "   macro avg       0.88      0.88      0.87       688\n",
      "weighted avg       0.88      0.88      0.87       688\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "yhat_classes = classifier.predict_classes(test_set, verbose=0)\n",
    "yhat_classes = yhat_classes[:, 0]\n",
    "\n",
    "print(classification_report(test_set.classes,yhat_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
