{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural Network\n",
    "\n",
    "### Part 1 - Building the CNN\n",
    "\n",
    "#### Importing the Tensorflow libraries and packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor Flow Version: 2.6.0\n",
      "Keras Version: 2.6.0\n",
      "\n",
      "Python 3.8.13 | packaged by conda-forge | (default, Mar 25 2022, 05:59:45) [MSC v.1929 64 bit (AMD64)]\n",
      "Pandas 1.4.3\n",
      "Scikit-Learn 1.1.1\n",
      "GPU is available\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "import tensorflow.keras\n",
    "import pandas as pd\n",
    "import sklearn as sk\n",
    "import tensorflow as tf\n",
    "\n",
    "print(f\"Tensor Flow Version: {tf.__version__}\")\n",
    "print(f\"Keras Version: {tensorflow.keras.__version__}\")\n",
    "print()\n",
    "print(f\"Python {sys.version}\")\n",
    "print(f\"Pandas {pd.__version__}\")\n",
    "print(f\"Scikit-Learn {sk.__version__}\")\n",
    "gpu = len(tf.config.list_physical_devices('GPU'))>0\n",
    "print(\"GPU is\", \"available\" if gpu else \"NOT AVAILABLE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the TensorBoard notebook extension\n",
    "%load_ext tensorboard\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, None, None, 3)]   0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, None, None, 64)    1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, None, None, 64)    36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, None, None, 64)    0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, None, None, 128)   73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, None, None, 128)   147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, None, None, 128)   0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, None, None, 256)   295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, None, None, 256)   590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, None, None, 256)   590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, None, None, 256)   0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, None, None, 512)   1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, None, None, 512)   0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, None, None, 512)   0         \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow.keras as keras\n",
    "\n",
    "vgg16 = keras.applications.vgg16\n",
    "conv_model = vgg16.VGG16(weights='imagenet', include_top=False)\n",
    "conv_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def plot_history(history, yrange):\n",
    "    '''Plot loss and accuracy as a function of the epoch,\n",
    "    for the training and validation datasets.\n",
    "    '''\n",
    "    acc = history.history['acc']\n",
    "    val_acc = history.history['val_acc']\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "\n",
    "    # Get number of epochs\n",
    "    epochs = range(len(acc))\n",
    "\n",
    "    # Plot training and validation accuracy per epoch\n",
    "    plt.plot(epochs, acc)\n",
    "    plt.plot(epochs, val_acc)\n",
    "    plt.title('Training and validation accuracy')\n",
    "    plt.ylim(yrange)\n",
    "    \n",
    "    # Plot training and validation loss per epoch\n",
    "    plt.figure()\n",
    "\n",
    "    plt.plot(epochs, loss)\n",
    "    plt.plot(epochs, val_loss)\n",
    "    plt.title('Training and validation loss')\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "def generators(shape, preprocessing): \n",
    "    '''Create the training and validation datasets for \n",
    "    a given image shape.\n",
    "    '''\n",
    "    path_dir = '../../dataset/train'\n",
    "    parth_dir_test = '../../dataset/test'\n",
    "\n",
    "    datagen = ImageDataGenerator(\n",
    "                    rescale=1./255,\n",
    "                    validation_split = 0.2)\n",
    "\n",
    "    train_dataset = datagen.flow_from_directory(\n",
    "        path_dir,\n",
    "        target_size=(150,150),\n",
    "        shuffle=True,\n",
    "        subset='training',\n",
    "        batch_size = 64,\n",
    "        class_mode = 'binary'\n",
    "    )\n",
    "    \n",
    "    val_dataset = datagen.flow_from_directory(\n",
    "        path_dir,\n",
    "        target_size=(150,150),\n",
    "        subset='validation',\n",
    "        batch_size = 64,\n",
    "        class_mode = 'binary'\n",
    "    )\n",
    "\n",
    "    test_dataset = datagen.flow_from_directory(parth_dir_test,\n",
    "                                        target_size= (150,150),\n",
    "                                        batch_size = 64,\n",
    "                                        class_mode = 'binary',\n",
    "                                        shuffle=False)\n",
    "    return train_dataset, val_dataset, test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2202 images belonging to 2 classes.\n",
      "Found 550 images belonging to 2 classes.\n",
      "Found 688 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_dataset, val_dataset, test_dataset = generators((150,150), preprocessing=vgg16.preprocess_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_model = vgg16.VGG16(weights='imagenet', include_top=False, input_shape=(150,150,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 150, 150, 3)]     0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 150, 150, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 150, 150, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 75, 75, 64)        0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 75, 75, 128)       73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 75, 75, 128)       147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 37, 37, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 37, 37, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 37, 37, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 37, 37, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 18, 18, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 18, 18, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 18, 18, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 18, 18, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 9, 9, 512)         0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 16)                131088    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 14,846,353\n",
      "Trainable params: 14,846,353\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# flatten the output of the convolutional part: \n",
    "x = keras.layers.Flatten()(conv_model.output)\n",
    "# three hidden layers\n",
    "x = keras.layers.Dense(16, activation='relu')(x)\n",
    "x = keras.layers.Dense(32, activation='relu')(x)\n",
    "x = keras.layers.Dropout(0.25)(x)\n",
    "\n",
    "# final softmax layer\n",
    "predictions = keras.layers.Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "# creating the full model:\n",
    "full_model = keras.models.Model(inputs=conv_model.input, outputs=predictions)\n",
    "full_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in conv_model.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 150, 150, 3)]     0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 150, 150, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 150, 150, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 75, 75, 64)        0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 75, 75, 128)       73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 75, 75, 128)       147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 37, 37, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 37, 37, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 37, 37, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 37, 37, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 18, 18, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 18, 18, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 18, 18, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 18, 18, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 9, 9, 512)         0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 16)                131088    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 14,846,353\n",
      "Trainable params: 131,665\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "full_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\envs\\gpu\\lib\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\optimizer_v2.py:374: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "full_model.compile(loss='binary_crossentropy',\n",
    "                  optimizer=keras.optimizers.Adamax(lr=0.001),\n",
    "                  metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, TensorBoard\n",
    "import datetime\n",
    "\n",
    "#rm -rf /logs/\n",
    "\n",
    "es = EarlyStopping(monitor='val_loss', patience=10)\n",
    "mc = ModelCheckpoint('best_vgg16.h5', monitor='val_loss', mode='min', save_best_only=True)\n",
    "reduceLR = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=20)\n",
    "\n",
    "# Create a TensorBoard callback\n",
    "log_dir = \"logs\\\\fit\\\\\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\envs\\gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1969: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/35\n",
      "35/35 [==============================] - 22s 396ms/step - loss: 0.6367 - acc: 0.6421 - val_loss: 0.5608 - val_acc: 0.8309\n",
      "Epoch 2/35\n",
      "35/35 [==============================] - 8s 216ms/step - loss: 0.5189 - acc: 0.7802 - val_loss: 0.4458 - val_acc: 0.8600\n",
      "Epoch 3/35\n",
      "35/35 [==============================] - 8s 219ms/step - loss: 0.4471 - acc: 0.8279 - val_loss: 0.3772 - val_acc: 0.8745\n",
      "Epoch 4/35\n",
      "35/35 [==============================] - 7s 212ms/step - loss: 0.3921 - acc: 0.8479 - val_loss: 0.3452 - val_acc: 0.8655\n",
      "Epoch 5/35\n",
      "35/35 [==============================] - 7s 211ms/step - loss: 0.3574 - acc: 0.8610 - val_loss: 0.3204 - val_acc: 0.8691\n",
      "Epoch 6/35\n",
      "35/35 [==============================] - 7s 212ms/step - loss: 0.3385 - acc: 0.8688 - val_loss: 0.2924 - val_acc: 0.8927\n",
      "Epoch 7/35\n",
      "35/35 [==============================] - 7s 212ms/step - loss: 0.3163 - acc: 0.8733 - val_loss: 0.2827 - val_acc: 0.8909\n",
      "Epoch 8/35\n",
      "35/35 [==============================] - 8s 215ms/step - loss: 0.3096 - acc: 0.8847 - val_loss: 0.2874 - val_acc: 0.8764\n",
      "Epoch 9/35\n",
      "35/35 [==============================] - 7s 212ms/step - loss: 0.2970 - acc: 0.8865 - val_loss: 0.3049 - val_acc: 0.8527\n",
      "Epoch 10/35\n",
      "35/35 [==============================] - 8s 223ms/step - loss: 0.2894 - acc: 0.8928 - val_loss: 0.2706 - val_acc: 0.8891\n",
      "Epoch 11/35\n",
      "35/35 [==============================] - 8s 225ms/step - loss: 0.2840 - acc: 0.8919 - val_loss: 0.3086 - val_acc: 0.8564\n",
      "Epoch 12/35\n",
      "35/35 [==============================] - 8s 217ms/step - loss: 0.2811 - acc: 0.8865 - val_loss: 0.2618 - val_acc: 0.8945\n",
      "Epoch 13/35\n",
      "35/35 [==============================] - 8s 216ms/step - loss: 0.2634 - acc: 0.8996 - val_loss: 0.2527 - val_acc: 0.8873\n",
      "Epoch 14/35\n",
      "35/35 [==============================] - 8s 226ms/step - loss: 0.2579 - acc: 0.8951 - val_loss: 0.2483 - val_acc: 0.8909\n",
      "Epoch 15/35\n",
      "35/35 [==============================] - 8s 224ms/step - loss: 0.2571 - acc: 0.8992 - val_loss: 0.2502 - val_acc: 0.8927\n",
      "Epoch 16/35\n",
      "35/35 [==============================] - 8s 214ms/step - loss: 0.2445 - acc: 0.9069 - val_loss: 0.2464 - val_acc: 0.8945\n",
      "Epoch 17/35\n",
      "35/35 [==============================] - 8s 219ms/step - loss: 0.2444 - acc: 0.9110 - val_loss: 0.2520 - val_acc: 0.8909\n",
      "Epoch 18/35\n",
      "35/35 [==============================] - 8s 221ms/step - loss: 0.2354 - acc: 0.9114 - val_loss: 0.2457 - val_acc: 0.9000\n",
      "Epoch 19/35\n",
      "35/35 [==============================] - 8s 224ms/step - loss: 0.2357 - acc: 0.9092 - val_loss: 0.2490 - val_acc: 0.8927\n",
      "Epoch 20/35\n",
      "35/35 [==============================] - 8s 215ms/step - loss: 0.2267 - acc: 0.9133 - val_loss: 0.2581 - val_acc: 0.8945\n",
      "Epoch 21/35\n",
      "35/35 [==============================] - 8s 219ms/step - loss: 0.2303 - acc: 0.9137 - val_loss: 0.2376 - val_acc: 0.9000\n",
      "Epoch 22/35\n",
      "35/35 [==============================] - 8s 213ms/step - loss: 0.2300 - acc: 0.9110 - val_loss: 0.2369 - val_acc: 0.9018\n",
      "Epoch 23/35\n",
      "35/35 [==============================] - 8s 222ms/step - loss: 0.2217 - acc: 0.9133 - val_loss: 0.2342 - val_acc: 0.9036\n",
      "Epoch 24/35\n",
      "35/35 [==============================] - 8s 223ms/step - loss: 0.2221 - acc: 0.9164 - val_loss: 0.2312 - val_acc: 0.9055\n",
      "Epoch 25/35\n",
      "35/35 [==============================] - 8s 237ms/step - loss: 0.2067 - acc: 0.9210 - val_loss: 0.2834 - val_acc: 0.8836\n",
      "Epoch 26/35\n",
      "35/35 [==============================] - 8s 227ms/step - loss: 0.2102 - acc: 0.9201 - val_loss: 0.2411 - val_acc: 0.8945\n",
      "Epoch 27/35\n",
      "35/35 [==============================] - 8s 221ms/step - loss: 0.2062 - acc: 0.9260 - val_loss: 0.2302 - val_acc: 0.9091\n",
      "Epoch 28/35\n",
      "35/35 [==============================] - 8s 219ms/step - loss: 0.2107 - acc: 0.9255 - val_loss: 0.2742 - val_acc: 0.8873\n",
      "Epoch 29/35\n",
      "35/35 [==============================] - 8s 220ms/step - loss: 0.1939 - acc: 0.9292 - val_loss: 0.2417 - val_acc: 0.8964\n",
      "Epoch 30/35\n",
      "35/35 [==============================] - 8s 226ms/step - loss: 0.1930 - acc: 0.9228 - val_loss: 0.2276 - val_acc: 0.9091\n",
      "Epoch 31/35\n",
      "35/35 [==============================] - 8s 220ms/step - loss: 0.1914 - acc: 0.9296 - val_loss: 0.2430 - val_acc: 0.8982\n",
      "Epoch 32/35\n",
      "35/35 [==============================] - 8s 213ms/step - loss: 0.1881 - acc: 0.9287 - val_loss: 0.2474 - val_acc: 0.8927\n",
      "Epoch 33/35\n",
      "35/35 [==============================] - 8s 218ms/step - loss: 0.1847 - acc: 0.9296 - val_loss: 0.2337 - val_acc: 0.9073\n",
      "Epoch 34/35\n",
      "35/35 [==============================] - 8s 231ms/step - loss: 0.1799 - acc: 0.9364 - val_loss: 0.2580 - val_acc: 0.8945\n",
      "Epoch 35/35\n",
      "35/35 [==============================] - 8s 214ms/step - loss: 0.1806 - acc: 0.9310 - val_loss: 0.2500 - val_acc: 0.8927\n"
     ]
    }
   ],
   "source": [
    "history = full_model.fit_generator(\n",
    "    train_dataset, \n",
    "    validation_data = val_dataset,\n",
    "    callbacks = [tensorboard_callback,es,mc,reduceLR],\n",
    "    epochs=35\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_history(history, yrange=(0,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-1917d342c54624ce\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-1917d342c54624ce\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir logs/fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_model.load_weights('best_vgg16.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model = full_model.load_weights('best_vgg16.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\envs\\gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:2030: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.25875217],\n",
       "       [0.06615838],\n",
       "       [0.05303687],\n",
       "       [0.03565032],\n",
       "       [0.03682791],\n",
       "       [0.21451384],\n",
       "       [0.15280415],\n",
       "       [0.19826117],\n",
       "       [0.07484489],\n",
       "       [0.05632036],\n",
       "       [0.04572728],\n",
       "       [0.14186926],\n",
       "       [0.05028199],\n",
       "       [0.07682029],\n",
       "       [0.01817393],\n",
       "       [0.02826154],\n",
       "       [0.04634168],\n",
       "       [0.4217715 ],\n",
       "       [0.1063908 ],\n",
       "       [0.04984231],\n",
       "       [0.0366298 ],\n",
       "       [0.03043098],\n",
       "       [0.1676509 ],\n",
       "       [0.03911208],\n",
       "       [0.09237797],\n",
       "       [0.15788661],\n",
       "       [0.07577689],\n",
       "       [0.05977419],\n",
       "       [0.05737253],\n",
       "       [0.03807099],\n",
       "       [0.04257024],\n",
       "       [0.05818539],\n",
       "       [0.04319995],\n",
       "       [0.10890147],\n",
       "       [0.06484909],\n",
       "       [0.01831013],\n",
       "       [0.02149642],\n",
       "       [0.01027155],\n",
       "       [0.01877405],\n",
       "       [0.61257035],\n",
       "       [0.607394  ],\n",
       "       [0.00701761],\n",
       "       [0.00768963],\n",
       "       [0.04438974],\n",
       "       [0.01772168],\n",
       "       [0.06803147],\n",
       "       [0.10026875],\n",
       "       [0.01384754],\n",
       "       [0.01413953],\n",
       "       [0.04322853],\n",
       "       [0.23913851],\n",
       "       [0.09516925],\n",
       "       [0.01219067],\n",
       "       [0.01082874],\n",
       "       [0.01676617],\n",
       "       [0.00960659],\n",
       "       [0.04419872],\n",
       "       [0.02683995],\n",
       "       [0.06015471],\n",
       "       [0.03430032],\n",
       "       [0.02804461],\n",
       "       [0.01221535],\n",
       "       [0.02823875],\n",
       "       [0.02032808],\n",
       "       [0.0256313 ],\n",
       "       [0.03480804],\n",
       "       [0.01766412],\n",
       "       [0.01383108],\n",
       "       [0.0167944 ],\n",
       "       [0.02729177],\n",
       "       [0.01580467],\n",
       "       [0.01859994],\n",
       "       [0.02170881],\n",
       "       [0.01671483],\n",
       "       [0.05116933],\n",
       "       [0.14405951],\n",
       "       [0.2185606 ],\n",
       "       [0.01556962],\n",
       "       [0.02404124],\n",
       "       [0.00928398],\n",
       "       [0.01037943],\n",
       "       [0.0939658 ],\n",
       "       [0.03435815],\n",
       "       [0.01408399],\n",
       "       [0.0106189 ],\n",
       "       [0.0433968 ],\n",
       "       [0.03722346],\n",
       "       [0.10753686],\n",
       "       [0.04307067],\n",
       "       [0.00514906],\n",
       "       [0.00688286],\n",
       "       [0.05384832],\n",
       "       [0.02792118],\n",
       "       [0.04670951],\n",
       "       [0.03497403],\n",
       "       [0.0366635 ],\n",
       "       [0.04348498],\n",
       "       [0.00414366],\n",
       "       [0.00551749],\n",
       "       [0.00472427],\n",
       "       [0.02726877],\n",
       "       [0.06441147],\n",
       "       [0.05348863],\n",
       "       [0.04262796],\n",
       "       [0.14483085],\n",
       "       [0.07353637],\n",
       "       [0.03398141],\n",
       "       [0.03392256],\n",
       "       [0.25300458],\n",
       "       [0.13325141],\n",
       "       [0.15495451],\n",
       "       [0.6484955 ],\n",
       "       [0.04933294],\n",
       "       [0.0243825 ],\n",
       "       [0.0177316 ],\n",
       "       [0.01499151],\n",
       "       [0.3698555 ],\n",
       "       [0.10454288],\n",
       "       [0.01732429],\n",
       "       [0.01586267],\n",
       "       [0.5246387 ],\n",
       "       [0.3626879 ],\n",
       "       [0.19348277],\n",
       "       [0.17715725],\n",
       "       [0.05921268],\n",
       "       [0.07324843],\n",
       "       [0.47054103],\n",
       "       [0.60759556],\n",
       "       [0.03210025],\n",
       "       [0.0142795 ],\n",
       "       [0.15119487],\n",
       "       [0.1381721 ],\n",
       "       [0.03955176],\n",
       "       [0.04985094],\n",
       "       [0.1637516 ],\n",
       "       [0.10730455],\n",
       "       [0.06485147],\n",
       "       [0.06985273],\n",
       "       [0.07493328],\n",
       "       [0.26132467],\n",
       "       [0.22682841],\n",
       "       [0.1317452 ],\n",
       "       [0.03595958],\n",
       "       [0.03840151],\n",
       "       [0.02688367],\n",
       "       [0.03327255],\n",
       "       [0.10018855],\n",
       "       [0.24339278],\n",
       "       [0.03202736],\n",
       "       [0.03497368],\n",
       "       [0.07020068],\n",
       "       [0.08752508],\n",
       "       [0.21323152],\n",
       "       [0.18595915],\n",
       "       [0.02319449],\n",
       "       [0.01204878],\n",
       "       [0.00918075],\n",
       "       [0.00423971],\n",
       "       [0.03893077],\n",
       "       [0.05213902],\n",
       "       [0.02024787],\n",
       "       [0.02001627],\n",
       "       [0.01090538],\n",
       "       [0.01899468],\n",
       "       [0.03892812],\n",
       "       [0.01493574],\n",
       "       [0.01290048],\n",
       "       [0.01799709],\n",
       "       [0.00916477],\n",
       "       [0.01108957],\n",
       "       [0.03642933],\n",
       "       [0.03899762],\n",
       "       [0.18476774],\n",
       "       [0.45134893],\n",
       "       [0.15793957],\n",
       "       [0.13560535],\n",
       "       [0.02806788],\n",
       "       [0.01094476],\n",
       "       [0.4472127 ],\n",
       "       [0.43592855],\n",
       "       [0.02807233],\n",
       "       [0.02845113],\n",
       "       [0.06268615],\n",
       "       [0.07173897],\n",
       "       [0.6519192 ],\n",
       "       [0.6042492 ],\n",
       "       [0.07663294],\n",
       "       [0.06689065],\n",
       "       [0.16264111],\n",
       "       [0.19501027],\n",
       "       [0.01378555],\n",
       "       [0.01390611],\n",
       "       [0.07154804],\n",
       "       [0.09009669],\n",
       "       [0.01704788],\n",
       "       [0.01493149],\n",
       "       [0.04556702],\n",
       "       [0.04205381],\n",
       "       [0.07644407],\n",
       "       [0.14669277],\n",
       "       [0.01189477],\n",
       "       [0.01250283],\n",
       "       [0.00851711],\n",
       "       [0.01371901],\n",
       "       [0.02096372],\n",
       "       [0.03951195],\n",
       "       [0.10088567],\n",
       "       [0.32527605],\n",
       "       [0.19616632],\n",
       "       [0.14600411],\n",
       "       [0.02553547],\n",
       "       [0.03153799],\n",
       "       [0.5679346 ],\n",
       "       [0.737084  ],\n",
       "       [0.01800969],\n",
       "       [0.02930051],\n",
       "       [0.13276833],\n",
       "       [0.08216685],\n",
       "       [0.01248801],\n",
       "       [0.01683166],\n",
       "       [0.03421703],\n",
       "       [0.02357747],\n",
       "       [0.32992205],\n",
       "       [0.58673036],\n",
       "       [0.80842566],\n",
       "       [0.6800128 ],\n",
       "       [0.05989724],\n",
       "       [0.21920456],\n",
       "       [0.52674234],\n",
       "       [0.48651826],\n",
       "       [0.02174018],\n",
       "       [0.02221871],\n",
       "       [0.44837838],\n",
       "       [0.38801077],\n",
       "       [0.4915301 ],\n",
       "       [0.5777284 ],\n",
       "       [0.03755455],\n",
       "       [0.09327511],\n",
       "       [0.08638092],\n",
       "       [0.3914733 ],\n",
       "       [0.02970719],\n",
       "       [0.1829682 ],\n",
       "       [0.02931751],\n",
       "       [0.06016517],\n",
       "       [0.01686125],\n",
       "       [0.01945844],\n",
       "       [0.17818677],\n",
       "       [0.16599153],\n",
       "       [0.02102103],\n",
       "       [0.04064672],\n",
       "       [0.04706107],\n",
       "       [0.07208002],\n",
       "       [0.01149715],\n",
       "       [0.13307373],\n",
       "       [0.14359145],\n",
       "       [0.06943879],\n",
       "       [0.18012908],\n",
       "       [0.0365368 ],\n",
       "       [0.00967695],\n",
       "       [0.01580524],\n",
       "       [0.06784068],\n",
       "       [0.09934164],\n",
       "       [0.01331106],\n",
       "       [0.02642954],\n",
       "       [0.04988272],\n",
       "       [0.10401703],\n",
       "       [0.01749617],\n",
       "       [0.02447622],\n",
       "       [0.01379139],\n",
       "       [0.02988739],\n",
       "       [0.01839574],\n",
       "       [0.0353651 ],\n",
       "       [0.01011687],\n",
       "       [0.02212556],\n",
       "       [0.00744806],\n",
       "       [0.0175892 ],\n",
       "       [0.14379038],\n",
       "       [0.10235133],\n",
       "       [0.3990937 ],\n",
       "       [0.4674614 ],\n",
       "       [0.11275258],\n",
       "       [0.05107673],\n",
       "       [0.03378543],\n",
       "       [0.02179868],\n",
       "       [0.08099838],\n",
       "       [0.05722311],\n",
       "       [0.02453944],\n",
       "       [0.02378337],\n",
       "       [0.85255027],\n",
       "       [0.5589832 ],\n",
       "       [0.00923548],\n",
       "       [0.01296873],\n",
       "       [0.6380984 ],\n",
       "       [0.66577065],\n",
       "       [0.6281    ],\n",
       "       [0.7715157 ],\n",
       "       [0.02960304],\n",
       "       [0.03192949],\n",
       "       [0.04565574],\n",
       "       [0.05625547],\n",
       "       [0.03346391],\n",
       "       [0.03649604],\n",
       "       [0.00740097],\n",
       "       [0.01902075],\n",
       "       [0.10019527],\n",
       "       [0.09972215],\n",
       "       [0.02085204],\n",
       "       [0.05192723],\n",
       "       [0.04524355],\n",
       "       [0.03160035],\n",
       "       [0.06273824],\n",
       "       [0.0609091 ],\n",
       "       [0.02510551],\n",
       "       [0.00921238],\n",
       "       [0.01425207],\n",
       "       [0.22945237],\n",
       "       [0.08562971],\n",
       "       [0.98777884],\n",
       "       [0.9920345 ],\n",
       "       [0.00840394],\n",
       "       [0.01742531],\n",
       "       [0.00739666],\n",
       "       [0.03047156],\n",
       "       [0.00925338],\n",
       "       [0.0097666 ],\n",
       "       [0.17516033],\n",
       "       [0.07665899],\n",
       "       [0.30907246],\n",
       "       [0.20006147],\n",
       "       [0.02514411],\n",
       "       [0.03808662],\n",
       "       [0.70747066],\n",
       "       [0.21653756],\n",
       "       [0.0873659 ],\n",
       "       [0.03865285],\n",
       "       [0.01829387],\n",
       "       [0.08985581],\n",
       "       [0.01276032],\n",
       "       [0.09604307],\n",
       "       [0.02077847],\n",
       "       [0.1365841 ],\n",
       "       [0.01945163],\n",
       "       [0.01955859],\n",
       "       [0.04029579],\n",
       "       [0.9859264 ],\n",
       "       [0.98590255],\n",
       "       [0.9540383 ],\n",
       "       [0.93587315],\n",
       "       [0.8703848 ],\n",
       "       [0.3816601 ],\n",
       "       [0.3064595 ],\n",
       "       [0.99511516],\n",
       "       [0.98666257],\n",
       "       [0.9933982 ],\n",
       "       [0.9920448 ],\n",
       "       [0.97744536],\n",
       "       [0.9359909 ],\n",
       "       [0.83027947],\n",
       "       [0.7601687 ],\n",
       "       [0.98539484],\n",
       "       [0.99567246],\n",
       "       [0.99270743],\n",
       "       [0.9885302 ],\n",
       "       [0.9977229 ],\n",
       "       [0.9925748 ],\n",
       "       [0.9960317 ],\n",
       "       [0.98484796],\n",
       "       [0.9824699 ],\n",
       "       [0.9490771 ],\n",
       "       [0.9510035 ],\n",
       "       [0.82507473],\n",
       "       [0.9935182 ],\n",
       "       [0.9867879 ],\n",
       "       [0.96080655],\n",
       "       [0.9794053 ],\n",
       "       [0.9713405 ],\n",
       "       [0.78573805],\n",
       "       [0.9857065 ],\n",
       "       [0.9899395 ],\n",
       "       [0.9293802 ],\n",
       "       [0.9317214 ],\n",
       "       [0.994902  ],\n",
       "       [0.9970304 ],\n",
       "       [0.97865206],\n",
       "       [0.957793  ],\n",
       "       [0.9663146 ],\n",
       "       [0.8797189 ],\n",
       "       [0.9997583 ],\n",
       "       [0.99820733],\n",
       "       [0.9411557 ],\n",
       "       [0.9221249 ],\n",
       "       [0.6526183 ],\n",
       "       [0.8888839 ],\n",
       "       [0.9882002 ],\n",
       "       [0.9898656 ],\n",
       "       [0.73444134],\n",
       "       [0.97658736],\n",
       "       [0.9948448 ],\n",
       "       [0.9962392 ],\n",
       "       [0.99605584],\n",
       "       [0.9936553 ],\n",
       "       [0.9053371 ],\n",
       "       [0.7862894 ],\n",
       "       [0.9538956 ],\n",
       "       [0.96085125],\n",
       "       [0.9931191 ],\n",
       "       [0.97756857],\n",
       "       [0.96744645],\n",
       "       [0.993353  ],\n",
       "       [0.97256124],\n",
       "       [0.9729172 ],\n",
       "       [0.9529134 ],\n",
       "       [0.99539596],\n",
       "       [0.9723804 ],\n",
       "       [0.9334317 ],\n",
       "       [0.9852486 ],\n",
       "       [0.97171974],\n",
       "       [0.98245853],\n",
       "       [0.99980205],\n",
       "       [0.99947935],\n",
       "       [0.7174858 ],\n",
       "       [0.7068705 ],\n",
       "       [0.9882316 ],\n",
       "       [0.9754032 ],\n",
       "       [0.2985326 ],\n",
       "       [0.19654024],\n",
       "       [0.9952989 ],\n",
       "       [0.9864429 ],\n",
       "       [0.9876512 ],\n",
       "       [0.97726905],\n",
       "       [0.88263786],\n",
       "       [0.5689832 ],\n",
       "       [0.4540961 ],\n",
       "       [0.99480313],\n",
       "       [0.9651571 ],\n",
       "       [0.9574066 ],\n",
       "       [0.99469584],\n",
       "       [0.98725325],\n",
       "       [0.9972631 ],\n",
       "       [0.99764156],\n",
       "       [0.9875136 ],\n",
       "       [0.95986974],\n",
       "       [0.99902284],\n",
       "       [0.9988366 ],\n",
       "       [0.99741983],\n",
       "       [0.9962915 ],\n",
       "       [0.75016713],\n",
       "       [0.3969498 ],\n",
       "       [0.996885  ],\n",
       "       [0.99581546],\n",
       "       [0.7200479 ],\n",
       "       [0.26590824],\n",
       "       [0.8886861 ],\n",
       "       [0.769249  ],\n",
       "       [0.99505347],\n",
       "       [0.9980653 ],\n",
       "       [0.99304444],\n",
       "       [0.9790244 ],\n",
       "       [0.03047964],\n",
       "       [0.05927612],\n",
       "       [0.42359805],\n",
       "       [0.13899212],\n",
       "       [0.99955064],\n",
       "       [0.9994337 ],\n",
       "       [0.9922213 ],\n",
       "       [0.9973609 ],\n",
       "       [0.5362999 ],\n",
       "       [0.980028  ],\n",
       "       [0.82784736],\n",
       "       [0.9172156 ],\n",
       "       [0.95646876],\n",
       "       [0.73156583],\n",
       "       [0.99301344],\n",
       "       [0.98905665],\n",
       "       [0.61689466],\n",
       "       [0.59717476],\n",
       "       [0.9995394 ],\n",
       "       [0.99953914],\n",
       "       [0.94200754],\n",
       "       [0.2974837 ],\n",
       "       [0.5739641 ],\n",
       "       [0.6186289 ],\n",
       "       [0.98778385],\n",
       "       [0.9826164 ],\n",
       "       [0.50783134],\n",
       "       [0.61703306],\n",
       "       [0.903366  ],\n",
       "       [0.6774524 ],\n",
       "       [0.9975617 ],\n",
       "       [0.99316365],\n",
       "       [0.99927086],\n",
       "       [0.9997353 ],\n",
       "       [0.992226  ],\n",
       "       [0.97765005],\n",
       "       [0.9995846 ],\n",
       "       [0.99963534],\n",
       "       [0.87796354],\n",
       "       [0.8336659 ],\n",
       "       [0.75784147],\n",
       "       [0.55486435],\n",
       "       [0.9628619 ],\n",
       "       [0.9118937 ],\n",
       "       [0.9934042 ],\n",
       "       [0.99389195],\n",
       "       [0.99461174],\n",
       "       [0.9917257 ],\n",
       "       [0.96331084],\n",
       "       [0.9420241 ],\n",
       "       [0.98216045],\n",
       "       [0.98423105],\n",
       "       [0.98701537],\n",
       "       [0.9836098 ],\n",
       "       [0.9791189 ],\n",
       "       [0.9711604 ],\n",
       "       [0.98744917],\n",
       "       [0.98631525],\n",
       "       [0.99121815],\n",
       "       [0.9601866 ],\n",
       "       [0.92984265],\n",
       "       [0.9503962 ],\n",
       "       [0.9721992 ],\n",
       "       [0.95054317],\n",
       "       [0.6428922 ],\n",
       "       [0.882764  ],\n",
       "       [0.7591671 ],\n",
       "       [0.8423944 ],\n",
       "       [0.9933954 ],\n",
       "       [0.9884537 ],\n",
       "       [0.9727585 ],\n",
       "       [0.96770257],\n",
       "       [0.5882513 ],\n",
       "       [0.99850947],\n",
       "       [0.9899324 ],\n",
       "       [0.9954835 ],\n",
       "       [0.7469707 ],\n",
       "       [0.43761507],\n",
       "       [0.98054606],\n",
       "       [0.95983285],\n",
       "       [0.94876593],\n",
       "       [0.7808031 ],\n",
       "       [0.97993875],\n",
       "       [0.99226874],\n",
       "       [0.9777996 ],\n",
       "       [0.9776577 ],\n",
       "       [0.8672633 ],\n",
       "       [0.9527431 ],\n",
       "       [0.9718624 ],\n",
       "       [0.96327114],\n",
       "       [0.9763632 ],\n",
       "       [0.9832375 ],\n",
       "       [0.99237615],\n",
       "       [0.99293464],\n",
       "       [0.960316  ],\n",
       "       [0.9725227 ],\n",
       "       [0.9949515 ],\n",
       "       [0.99722385],\n",
       "       [0.9962748 ],\n",
       "       [0.9948886 ],\n",
       "       [0.9956405 ],\n",
       "       [0.9964574 ],\n",
       "       [0.9944718 ],\n",
       "       [0.9836948 ],\n",
       "       [0.9940487 ],\n",
       "       [0.9862037 ],\n",
       "       [0.99780494],\n",
       "       [0.99501723],\n",
       "       [0.9113921 ],\n",
       "       [0.9537336 ],\n",
       "       [0.3887178 ],\n",
       "       [0.29097566],\n",
       "       [0.9870105 ],\n",
       "       [0.9928639 ],\n",
       "       [0.98194236],\n",
       "       [0.99826616],\n",
       "       [0.94233716],\n",
       "       [0.99709785],\n",
       "       [0.2641722 ],\n",
       "       [0.13516802],\n",
       "       [0.00305256],\n",
       "       [0.00740487],\n",
       "       [0.8081416 ],\n",
       "       [0.73208386],\n",
       "       [0.8682371 ],\n",
       "       [0.2367861 ],\n",
       "       [0.99357927],\n",
       "       [0.9571711 ],\n",
       "       [0.97571564],\n",
       "       [0.9804273 ],\n",
       "       [0.9943475 ],\n",
       "       [0.9930911 ],\n",
       "       [0.9991571 ],\n",
       "       [0.996561  ],\n",
       "       [0.9729541 ],\n",
       "       [0.9801222 ],\n",
       "       [0.9809202 ],\n",
       "       [0.99267864],\n",
       "       [0.6877175 ],\n",
       "       [0.82086337],\n",
       "       [0.9728072 ],\n",
       "       [0.98550713],\n",
       "       [0.97836393],\n",
       "       [0.994441  ],\n",
       "       [0.9860072 ],\n",
       "       [0.97873026],\n",
       "       [0.9920189 ],\n",
       "       [0.99156743],\n",
       "       [0.9952637 ],\n",
       "       [0.99722975],\n",
       "       [0.74229026],\n",
       "       [0.6182426 ],\n",
       "       [0.9846036 ],\n",
       "       [0.9916087 ],\n",
       "       [0.9949837 ],\n",
       "       [0.9904004 ],\n",
       "       [0.99298143],\n",
       "       [0.9916447 ],\n",
       "       [0.99741864],\n",
       "       [0.9980925 ],\n",
       "       [0.96025014],\n",
       "       [0.9818333 ],\n",
       "       [0.9897703 ],\n",
       "       [0.9919036 ],\n",
       "       [0.99970526],\n",
       "       [0.9995485 ],\n",
       "       [0.99402076],\n",
       "       [0.9963342 ],\n",
       "       [0.99151355],\n",
       "       [0.9900153 ],\n",
       "       [0.9845221 ],\n",
       "       [0.99233764],\n",
       "       [0.9665844 ],\n",
       "       [0.93224716],\n",
       "       [0.9726073 ],\n",
       "       [0.92132473],\n",
       "       [0.95506793],\n",
       "       [0.9943456 ],\n",
       "       [0.8002345 ],\n",
       "       [0.95013523],\n",
       "       [0.9896744 ],\n",
       "       [0.99008113]], dtype=float32)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_pred = full_model.predict_generator(test_dataset, test_dataset.samples // test_dataset.batch_size)\n",
    "Y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 150, 150, 3)]     0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 150, 150, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 150, 150, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 75, 75, 64)        0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 75, 75, 128)       73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 75, 75, 128)       147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 37, 37, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 37, 37, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 37, 37, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 37, 37, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 18, 18, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 18, 18, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 18, 18, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 18, 18, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 9, 9, 512)         0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 16)                131088    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 14,846,353\n",
      "Trainable params: 131,665\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "full_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss 0.18763229250907898\n",
      "Test accuracy 0.9316860437393188\n"
     ]
    }
   ],
   "source": [
    "score = full_model.evaluate(test_dataset, verbose=0)\n",
    "\n",
    "print('Test Loss', score[0])\n",
    "print('Test accuracy', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Overfitting -> Your training accuracy will be higher than the accuracy on the validation/test set\n",
    "\n",
    "#Overfitting indicates that your model is too complex for the problem that it is solving,\n",
    "#filters in the case of Convolutional Neural Networks, and layers in the case of overall Deep Learning Models\n",
    "\n",
    "#How do you know if your model is underfitting? Your model is underfitting if the accuracy on the validation set \n",
    "#is higher than the accuracy on the training set. Additionally, \n",
    "#if the whole model performs bad this is also called underfitting.\n",
    "\n",
    "#https://towardsdatascience.com/deep-learning-3-more-on-cnns-handling-overfitting-2bd5d99abe5d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0], dtype=int64)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "y_pred = np.argmax(Y_pred, axis=1)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
